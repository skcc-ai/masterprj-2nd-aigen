"""
CodeChat Agent - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰(FTS+FAISS) + RAG ê¸°ë°˜ ì½”ë“œ ì±„íŒ…
ì½”ë“œë² ì´ìŠ¤ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ê´€ë ¨ ì½”ë“œë¥¼ ì°¾ì•„ì„œ ì œì‹œ
"""

import os
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import numpy as np

from openai import AzureOpenAI
from common.store.sqlite_store import SQLiteStore
from .simple_context_manager import SimpleContextManager, ConversationContext
from .simple_evaluator import SimpleSelfEvaluator, SimpleEvaluation

logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """ê²€ìƒ‰ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    symbol_name: str
    symbol_type: str
    file_path: str
    start_line: int
    end_line: int
    content: str
    source: str
    similarity_score: float
    input_types: Optional[str] = None
    output_types: Optional[str] = None
    dependencies: Optional[List[str]] = None
    usage_examples: Optional[str] = None

@dataclass
class ChatResponse:
    """ì±„íŒ… ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    answer: str
    evidence: List[SearchResult]
    confidence: float

class CodeChatAgent:
    """ì½”ë“œ ì±„íŒ… ì—ì´ì „íŠ¸ - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + RAG"""
    
    def __init__(self, repo_path: str = ".", artifacts_dir: str = "./artifacts", data_dir: str = "./data"):
        """
        CodeChatAgent ì´ˆê¸°í™”
        
        Args:
            repo_path: ì½”ë“œë² ì´ìŠ¤ ê²½ë¡œ
            artifacts_dir: ë²¡í„° ìŠ¤í† ì–´ê°€ ì €ì¥ëœ ë””ë ‰í† ë¦¬
            data_dir: SQLite ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬
        """
        self.repo_path = Path(repo_path)
        self.artifacts_dir = Path(artifacts_dir)
        self.data_dir = Path(data_dir)
        
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._init_openai_client()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë° ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self._init_data_sources()
        
        # AI ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì´ˆê¸°í™”
        self._init_ai_context_manager()
        
        # AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._init_self_evaluator()
        
        logger.info(f"CodeChatAgent ì´ˆê¸°í™” ì™„ë£Œ: {self.repo_path}")
    
    def _init_openai_client(self):
        """Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            api_key = os.getenv("AZURE_OPENAI_API_KEY")
            endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
            api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2025-01-01-preview")
            
            # ì±„íŒ…ìš© ëª¨ë¸ (gpt-4o)
            deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4o")
            
            # embeddingsìš© ëª¨ë¸
            embedding_deployment = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT", "text-embedding-3-large")
            
            if not api_key or not endpoint:
                raise ValueError("Azure OpenAI API í‚¤ì™€ ì—”ë“œí¬ì¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤")
            
            self.openai_client = AzureOpenAI(
                api_key=api_key,
                azure_endpoint=endpoint,
                api_version=api_version
            )
            self.deployment_name = deployment_name
            self.embedding_deployment = embedding_deployment
            
            logger.info(f"Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {deployment_name}, ì„ë² ë”©: {embedding_deployment})")
            
        except Exception as e:
            logger.error(f"Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _init_data_sources(self):
        """ë°ì´í„° ì†ŒìŠ¤ ì´ˆê¸°í™”"""
        try:
            # SQLite ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            self.sqlite_store = SQLiteStore(self.data_dir / "structsynth_code.db")
            
            # StructSynthAgent ì´ˆê¸°í™” (ê°œì„ ëœ ê²€ìƒ‰ ê¸°ëŠ¥ ì‚¬ìš©)
            try:
                from agents.structsynth.agent import StructSynthAgent
                self.structsynth_agent = StructSynthAgent(
                    repo_path=str(self.repo_path),
                    artifacts_dir=str(self.artifacts_dir),
                    data_dir=str(self.data_dir)
                )
                logger.info("StructSynthAgent ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"StructSynthAgent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.structsynth_agent = None
            
            # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
            self._load_vector_store()
            
            logger.info("ë°ì´í„° ì†ŒìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def _init_ai_context_manager(self):
        """ë‹¨ìˆœ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”"""
        try:
            # ë‹¨ìˆœ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™”
            self.context_manager = SimpleContextManager(max_context_size=10)
            
            logger.info("ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ê¸°ëŠ¥ì€ ë™ì‘í•˜ë„ë¡ í•¨
            self.context_manager = None
    
    def _init_self_evaluator(self):
        """AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # ê°„ë‹¨í•œ AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self.self_evaluator = SimpleSelfEvaluator(
                self.openai_client,
                self.deployment_name
            )
            
            logger.info("AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # í‰ê°€ ì‹œìŠ¤í…œ ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ê¸°ëŠ¥ì€ ë™ì‘í•˜ë„ë¡ í•¨
            self.self_evaluator = None
    
    def _load_vector_store(self):
        """ë²¡í„° ìŠ¤í† ì–´ë¥¼ SQLiteì™€ FAISSì—ì„œ ë¡œë“œ"""
        try:
            # 1. SQLite embeddings í…Œì´ë¸”ì—ì„œ ë²¡í„° ë°ì´í„° ë¡œë“œ
            embeddings_data = self.sqlite_store.get_all_embeddings()
            
            if embeddings_data:
                # ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„° êµ¬ì„±
                self.vectors = []
                self.metadata = []
                
                for emb in embeddings_data:
                    try:
                        # bytes -> numpy array ë³€í™˜
                        vector = np.frombuffer(emb['vector'], dtype=np.float32)
                        self.vectors.append(vector)
                        
                        # chunks í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                        chunk_info = self.sqlite_store.get_chunk_info(emb['object_id'])
                        if chunk_info:
                            # SearchResult í˜•ì‹ì— ë§ê²Œ ë©”íƒ€ë°ì´í„° êµ¬ì„±
                            metadata = {
                                "symbol_name": chunk_info.get('symbol_name', ''),
                                "symbol_type": chunk_info.get('symbol_type', ''),
                                "file_path": chunk_info.get('file_path', ''),
                                "start_line": chunk_info.get('start_line', 0),
                                "end_line": chunk_info.get('end_line', 0),
                                "content": chunk_info.get('content', ''),
                                "chunk_id": emb['object_id']
                            }
                            self.metadata.append(metadata)
                        else:
                            logger.warning(f"ì²­í¬ {emb['object_id']} ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                            
                    except Exception as e:
                        logger.warning(f"ì„ë² ë”© {emb['id']} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        continue
                
                logger.info(f"SQLiteì—ì„œ ë²¡í„° ë¡œë“œ ì™„ë£Œ: {len(self.vectors)}ê°œ")
                
                # 2. FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„
                self._load_faiss_index()
                
            else:
                logger.warning("embeddings í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                self.vectors = None
                self.metadata = None
                
        except Exception as e:
            logger.error(f"ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.vectors = None
            self.metadata = None
    
    def _load_faiss_index(self):
        """FAISS ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            # FAISS ì¸ë±ìŠ¤ íŒŒì¼ ê²½ë¡œ í™•ì¸
            faiss_index_path = self.artifacts_dir / "faiss.index"
            
            if faiss_index_path.exists():
                # FAISSStore ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ ë¡œë“œ
                from common.store.faiss_store import FAISSStore
                
                self.faiss_store = FAISSStore(
                    index_path=str(faiss_index_path),
                    dimension=3072  # text-embedding-3-large ì°¨ì›
                )
                
                # ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ
                if hasattr(self.faiss_store, 'load_or_create_index'):
                    self.faiss_store.load_or_create_index()
                    logger.info("FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.info("FAISS ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
                    
            else:
                logger.warning(f"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {faiss_index_path}")
                self.faiss_store = None
                
        except Exception as e:
            logger.error(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.faiss_store = None
    
    def chat(self, query: str, top_k: int = 10, session_id: str = "default", 
             user_id: Optional[str] = None) -> ChatResponse:
        """ê°œì„ ëœ ì±„íŒ… ì‘ë‹µ ìƒì„± - AI ê¸°ë°˜ ë„êµ¬ ì„ íƒ"""
        try:
            # query ê²€ì¦ ë° ìƒì„¸ ë¡œê¹…
            logger.info(f"ì±„íŒ… ìš”ì²­ ìˆ˜ì‹  - query íƒ€ì…: {type(query)}, ê°’: '{query}'")
            
            if query is None:
                logger.warning("ì±„íŒ… ìš”ì²­ ë¬´íš¨: queryê°€ None")
                return ChatResponse(
                    answer="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                    evidence=[],
                    confidence=0.0
                )
            
            if not isinstance(query, str):
                logger.warning(f"ì±„íŒ… ìš”ì²­ ë¬´íš¨: queryê°€ ë¬¸ìì—´ì´ ì•„ë‹˜ (íƒ€ì…: {type(query)})")
                return ChatResponse(
                    answer="ì§ˆë¬¸ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.",
                    evidence=[],
                    confidence=0.0
                )
            
            if not query.strip():
                logger.warning("ì±„íŒ… ìš”ì²­ ë¬´íš¨: queryê°€ ë¹„ì–´ ìˆìŒ (ê³µë°±ë§Œ í¬í•¨)")
                return ChatResponse(
                    answer="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                    evidence=[],
                    confidence=0.0
                )
            
            # ê³µë°± ì œê±°ëœ query ì‚¬ìš©
            query = query.strip()
            logger.info(f"ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: '{query}' (ì„¸ì…˜: {session_id})")
            
            # 1. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            context = {}
            if self.context_manager:
                try:
                    context = self.context_manager.get_context_for_query(session_id, query)
                    logger.info(f"ğŸ’¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ: {context.get('total_conversations', 0)}ê°œ ëŒ€í™” ê¸°ë¡")
                    if context.get('mentioned_symbols'):
                        logger.info(f"   - ì–¸ê¸‰ëœ ì‹¬ë³¼ë“¤: {context['mentioned_symbols'][:3]}")
                    if context.get('mentioned_files'):
                        logger.info(f"   - ì–¸ê¸‰ëœ íŒŒì¼ë“¤: {context['mentioned_files'][:3]}")
                except Exception as e:
                    logger.warning(f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # 2. AI ê¸°ë°˜ ì§ˆë¬¸ ë¶„ì„ ë° ë„êµ¬ ì„ íƒ (ì»¨í…ìŠ¤íŠ¸ í™œìš©)
            logger.info("AI ê¸°ë°˜ ì§ˆë¬¸ ë¶„ì„ ì‹œì‘")
            tool_selection = self._analyze_query_and_select_tools(query, context)
            
            # ë„êµ¬ ì„ íƒ ê²°ê³¼ ë¡œê¹…
            logger.info(f"ğŸ” ì§ˆë¬¸ ë¶„ì„ ê²°ê³¼:")
            logger.info(f"   - ì§ˆë¬¸ ìœ í˜•: {tool_selection['query_type']}")
            logger.info(f"   - ì„ íƒëœ ë„êµ¬: {tool_selection['selected_tools']}")
            logger.info(f"   - ì„ íƒ ì´ìœ : {tool_selection['reasoning']}")
            if tool_selection.get('artifact_name'):
                logger.info(f"   - ì‚°ì¶œë¬¼ íŒŒì¼: {tool_selection['artifact_name']}")
            
            # 3. ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ì²˜ë¦¬
            if tool_selection["query_type"] == "overview":
                # ê°œìš”/ì „ë°˜ì  ì§ˆë¬¸: get_artifact ì‚¬ìš©
                logger.info("ğŸ“„ ê°œìš” ì§ˆë¬¸ ê°ì§€ - ì‚°ì¶œë¬¼ ê¸°ë°˜ ë‹µë³€ ìƒì„±")
                response = self._handle_overview_query(query, tool_selection)
            else:
                # íŠ¹ì • ì½”ë“œ ì§ˆë¬¸: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + LLM ë¶„ì„
                logger.info("ğŸ” íŠ¹ì • ì½”ë“œ ì§ˆë¬¸ ê°ì§€ - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰")
                response = self._handle_specific_query(query, tool_selection, top_k)
            
            # 4. AI ììœ¨ í‰ê°€ ë° ê°œì„  (3ë²ˆ ì‹œë„ í›„ ìµœê³  ì ìˆ˜ ì„ íƒ)
            if self.self_evaluator:
                try:
                    logger.info("ğŸ¤– AI ììœ¨ í‰ê°€ ë° ë‹¤ì¤‘ ì‹œë„ ê°œì„  ì‹œì‘")
                    
                    # ìµœëŒ€ 3ë²ˆ ì‹œë„í•˜ì—¬ ê°€ì¥ ì¢‹ì€ ë‹µë³€ ì„ íƒ
                    best_answer = response.answer
                    best_evaluation = None
                    best_score = 0.0
                    attempts = []
                    
                    for attempt in range(3):
                        logger.info(f"ğŸ”„ ê°œì„  ì‹œë„ {attempt + 1}/3")
                        
                        try:
                            # ê° ì‹œë„ë§ˆë‹¤ ë‹µë³€ ê°œì„ 
                            current_answer = response.answer if attempt == 0 else best_answer
                            improved_answer, evaluation = self.self_evaluator.evaluate_and_improve(
                                question=query,
                                answer=current_answer,
                                context=context,
                                codechat_agent=self,
                                attempt_number=attempt + 1
                            )
                            
                            # ì ìˆ˜ ê¸°ë¡
                            current_score = evaluation.score if evaluation else 0.0
                            attempts.append({
                                "attempt": attempt + 1,
                                "answer": improved_answer,
                                "evaluation": evaluation,
                                "score": current_score
                            })
                            
                            logger.info(f"   ì‹œë„ {attempt + 1} ì ìˆ˜: {current_score:.1f}/100")
                            
                            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì¸ ê²½ìš° ì—…ë°ì´íŠ¸
                            if current_score > best_score:
                                best_score = current_score
                                best_answer = improved_answer
                                best_evaluation = evaluation
                                logger.info(f"   âœ¨ ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜! {current_score:.1f}/100")
                            
                            # ì ìˆ˜ê°€ 95ì  ì´ìƒì´ë©´ ë” ì´ìƒ ì‹œë„í•˜ì§€ ì•ŠìŒ
                            if current_score >= 95.0:
                                logger.info(f"   ğŸ¯ ìš°ìˆ˜í•œ ì ìˆ˜ ë‹¬ì„± ({current_score:.1f}), ì¶”ê°€ ì‹œë„ ì¤‘ë‹¨")
                                break
                                
                        except Exception as e:
                            logger.warning(f"   âŒ ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
                            attempts.append({
                                "attempt": attempt + 1,
                                "answer": response.answer,
                                "evaluation": None,
                                "score": 0.0,
                                "error": str(e)
                            })
                            continue
                    
                    # ìµœê³  ì ìˆ˜ ë‹µë³€ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                    response.answer = best_answer
                    
                    # ìµœì¢… í‰ê°€ ê²°ê³¼ ë¡œê¹…
                    logger.info(f"ğŸ† ë‹¤ì¤‘ ì‹œë„ ì™„ë£Œ - ìµœì¢… ì„ íƒ:")
                    logger.info(f"   - ìµœê³  ì ìˆ˜: {best_score:.1f}/100")
                    if best_evaluation:
                        logger.info(f"   - ì¶©ë¶„í•¨: {best_evaluation.is_sufficient}")
                        if best_evaluation.missing_parts:
                            logger.info(f"   - ë¶€ì¡±í•œ ë¶€ë¶„: {', '.join(best_evaluation.missing_parts)}")
                        if best_evaluation.feedback:
                            logger.info(f"   - í”¼ë“œë°±: {best_evaluation.feedback}")
                    
                    # ëª¨ë“  ì‹œë„ ìš”ì•½
                    logger.info("ğŸ“‹ ì „ì²´ ì‹œë„ ìš”ì•½:")
                    for att in attempts:
                        if "error" in att:
                            logger.info(f"   ì‹œë„ {att['attempt']}: ì‹¤íŒ¨ ({att['error'][:50]}...)")
                        else:
                            logger.info(f"   ì‹œë„ {att['attempt']}: {att['score']:.1f}ì ")
                    
                except Exception as e:
                    logger.error(f"âŒ AI ììœ¨ í‰ê°€ ì „ì²´ ì‹¤íŒ¨: {e}")
                    logger.info("ğŸ”„ ì›ë³¸ ë‹µë³€ ìœ ì§€")
            
            # 5. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
            if self.context_manager:
                try:
                    # SearchResultë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                    search_results = []
                    for evidence in response.evidence:
                        search_results.append({
                            "symbol_name": evidence.symbol_name,
                            "file_path": evidence.file_path,
                            "symbol_type": evidence.symbol_type,
                            "content": evidence.content[:200] + "..." if len(evidence.content) > 200 else evidence.content
                        })
                    
                    self.context_manager.add_conversation(
                        session_id=session_id,
                        query=query,
                        answer=response.answer,
                        search_results=search_results,
                        query_type=tool_selection.get("query_type", "specific"),
                        tools_used=tool_selection.get("selected_tools", [])
                    )
                    logger.info("ğŸ’¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            
            return response
            
        except Exception as e:
            logger.error(f"ì±„íŒ… ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return ChatResponse(
                answer=f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                evidence=[],
                confidence=0.0
            )
    
    def _detect_general_query(self, query: str) -> bool:
        """ì¼ë°˜ì ì¸ ì§ˆë¬¸ì¸ì§€ ê°ì§€"""
        if not query or not isinstance(query, str):
            return False
            
        general_keywords = [
            "ì „ì²´", "ì „ë°˜", "overview", "summary", "êµ¬ì¡°", "ì•„í‚¤í…ì²˜",
            "ë¶„ì„í•´ì¤˜", "ì„¤ëª…í•´ì¤˜", "ìš”ì•½í•´ì¤˜", "ê°œìš”", "ì „ì²´ì ìœ¼ë¡œ", "ì „ë°˜ì ìœ¼ë¡œ"
        ]
        
        query_lower = query.lower()
        return any(keyword in query_lower for keyword in general_keywords)
    
    def _handle_general_analysis(self, query: str) -> str:
        """ì „ì²´ ì½”ë“œ ë¶„ì„ ì²˜ë¦¬"""
        try:
            logger.info("ì „ì²´ ì½”ë“œ ë¶„ì„ ì‹œì‘")
            
            # 1. ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ìˆ˜ì§‘
            stats = self.sqlite_store.get_database_stats()
            
            # 2. ì£¼ìš” íŒŒì¼ ë° ì‹¬ë³¼ ì •ë³´ ìˆ˜ì§‘
            files = self.sqlite_store.get_all_files()
            symbols = self.sqlite_store.get_all_symbols()
            
            # 3. ì „ì²´ êµ¬ì¡° ë¶„ì„ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_overview_context(stats, files, symbols)
            
            # 4. LLMì„ í†µí•œ ì „ì²´ ë¶„ì„
            return self._generate_overview_analysis(query, context)
            
        except Exception as e:
            logger.error(f"ì „ì²´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "ì „ì²´ ì½”ë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def _build_overview_context(self, stats: Dict[str, Any], files: List[Dict], symbols: List[Dict]) -> str:
        """ì „ì²´ ë¶„ì„ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        context_parts = []
        
        # í†µê³„ ì •ë³´
        context_parts.append(f"""
        [í”„ë¡œì íŠ¸ ê°œìš”]
        ì´ íŒŒì¼ ìˆ˜: {stats.get('total_files', 0)}
        ì´ ì‹¬ë³¼ ìˆ˜: {stats.get('total_symbols', 0)}
        ì´ ì²­í¬ ìˆ˜: {stats.get('total_chunks', 0)}
        """)
        
        # íŒŒì¼ êµ¬ì¡°
        if files:
            context_parts.append("\n[íŒŒì¼ êµ¬ì¡°]")
            for file_info in files[:10]:  # ìƒìœ„ 10ê°œ íŒŒì¼ë§Œ
                context_parts.append(f"- {file_info.get('path', 'unknown')} ({file_info.get('language', 'unknown')})")
                if file_info.get('llm_summary'):
                    context_parts.append(f"  ìš”ì•½: {file_info.get('llm_summary')}")
        
        # ì‹¬ë³¼ ë¶„í¬
        if symbols:
            symbol_types = {}
            for symbol in symbols:
                symbol_type = symbol.get('type', 'unknown')
                symbol_types[symbol_type] = symbol_types.get(symbol_type, 0) + 1
            
            context_parts.append("\n[ì‹¬ë³¼ ë¶„í¬]")
            for symbol_type, count in symbol_types.items():
                context_parts.append(f"- {symbol_type}: {count}ê°œ")
        
        return "\n".join(context_parts)
    
    def _generate_overview_analysis(self, query: str, context: str) -> str:
        """ì „ì²´ ë¶„ì„ì„ ìœ„í•œ LLM ì‘ë‹µ ìƒì„±"""
        try:
            prompt = f"""
            ë‹¤ìŒ ì½”ë“œë² ì´ìŠ¤ì— ëŒ€í•œ ì „ì²´ì ì¸ ë¶„ì„ì„ ìš”ì²­ë°›ì•˜ìŠµë‹ˆë‹¤:
            
            ì§ˆë¬¸: {query}
            
            ì½”ë“œë² ì´ìŠ¤ ì»¨í…ìŠ¤íŠ¸:
            {context}
            
            ìš”êµ¬ì‚¬í•­:
            1. ì½”ë“œë² ì´ìŠ¤ì˜ ì „ì²´ì ì¸ êµ¬ì¡°ì™€ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”
            2. ì£¼ìš” íŒŒì¼ë“¤ì˜ ì—­í• ê³¼ ì±…ì„ì„ ìš”ì•½í•´ì£¼ì„¸ìš”
            3. ì‹¬ë³¼ ë¶„í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì½”ë“œì˜ ë³µì¡ë„ì™€ íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”
            4. ì „ë°˜ì ì¸ ì•„í‚¤í…ì²˜ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”
            5. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
            """
            
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì „ì²´ì ì¸ ê´€ì ì—ì„œ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            answer = response.choices[0].message.content
            logger.info("ì „ì²´ ë¶„ì„ ì™„ë£Œ")
            return answer
            
        except Exception as e:
            logger.error(f"ì „ì²´ ë¶„ì„ LLM ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ì „ì²´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _hybrid_search(self, query: str, top_k: int) -> List[SearchResult]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (StructSynthAgent ìš°ì„  + ê¸°ì¡´ ë°©ì‹ fallback)"""
        try:
            # query ê²€ì¦ ì¶”ê°€
            if not query or not isinstance(query, str):
                logger.warning("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë¬´íš¨: queryê°€ ë¹„ì–´ ìˆìŒ")
                return []
            
            logger.info(f"=== _hybrid_search ì‹œì‘: '{query}', top_k={top_k} ===")
            logger.info(f"structsynth_agent ì¡´ì¬ ì—¬ë¶€: {hasattr(self, 'structsynth_agent')}")
            logger.info(f"structsynth_agent ê°’: {self.structsynth_agent}")
        
            # FTS ê²€ìƒ‰ (SQLite)
            fts_results = self._fts_search(query, top_k)
            
            # FAISS ê²€ìƒ‰ (ë²¡í„° ìœ ì‚¬ë„)
            faiss_results = self._faiss_search(query, top_k)
            
            # None ì²´í¬ ë° ì•ˆì „ ì²˜ë¦¬
            if faiss_results is None:
                logger.warning("FAISS ê²€ìƒ‰ ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.")
                faiss_results = []
            
            # ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°
            merged_results = self._merge_search_results(fts_results, faiss_results, top_k)
            
            logger.info(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(merged_results)}ê°œ ê²°ê³¼")
            return merged_results
            
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return []
    
    def _fts_search(self, query: str, top_k: int) -> List[SearchResult]:
        """SQLite FTS ê²€ìƒ‰"""
        try:
            # query ê²€ì¦ ì¶”ê°€
            if not query or not isinstance(query, str):
                logger.warning("FTS ê²€ìƒ‰ ë¬´íš¨: queryê°€ ë¹„ì–´ ìˆìŒ")
                return []
            
            # SQLiteì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰
            results = self.sqlite_store.search_symbols_fts(query, top_k)
            
            fts_results = []
            for result in results:
                search_result = SearchResult(
                    symbol_name=result.get("name", ""),
                    symbol_type=result.get("type", ""),
                    file_path=result.get("file_path", ""),
                    start_line=result.get("start_line", 0),
                    end_line=result.get("end_line", 0),
                    content=result.get("content", ""),
                    source="fts",
                    similarity_score=result.get("relevance_score", 0.0),
                    input_types=result.get("input_types"),
                    output_types=result.get("output_types"),
                    dependencies=result.get("dependencies"),
                    usage_examples=result.get("usage_examples")
                )
                fts_results.append(search_result)
            
            logger.info(f"FTS ê²€ìƒ‰ ì™„ë£Œ: {len(fts_results)}ê°œ ê²°ê³¼")
            return fts_results
            
        except Exception as e:
            logger.error(f"FTS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _faiss_search(self, query: str, top_k: int) -> List[SearchResult]:
        """FAISS ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
        try:
            # query ê²€ì¦ ì¶”ê°€
            if not query or not isinstance(query, str):
                logger.warning("FAISS ê²€ìƒ‰ ë¬´íš¨: queryê°€ ë¹„ì–´ ìˆìŒ")
                return []
            
            logger.info(f"=== FAISS ê²€ìƒ‰ ì‹œì‘: '{query}', top_k={top_k} ===")
            
            # FAISS ì¸ë±ìŠ¤ ìƒíƒœ ë¡œê¹…
            if hasattr(self, 'faiss_store'):
                logger.info(f"FAISS ì¸ë±ìŠ¤ ì¡´ì¬: {self.faiss_store is not None}")
                if self.faiss_store is not None:
                    logger.info(f"FAISS ì¸ë±ìŠ¤ íƒ€ì…: {type(self.faiss_store)}")
                    logger.info(f"FAISS ì¸ë±ìŠ¤ ë©”ì„œë“œ: {[method for method in dir(self.faiss_store) if not method.startswith('_')]}")
            else:
                logger.info("FAISS ì¸ë±ìŠ¤ ì†ì„±ì´ ì—†ìŒ")
            
            # ë¡œì»¬ ë²¡í„° ìƒíƒœ ë¡œê¹…
            logger.info(f"ë¡œì»¬ ë²¡í„° ì¡´ì¬: {self.vectors is not None}")
            if self.vectors is not None:
                logger.info(f"ë¡œì»¬ ë²¡í„° ê°œìˆ˜: {len(self.vectors)}")
                logger.info(f"ë¡œì»¬ ë²¡í„° ì°¨ì›: {self.vectors[0].shape if len(self.vectors) > 0 else 'N/A'}")
            
            logger.info(f"ë¡œì»¬ ë©”íƒ€ë°ì´í„° ì¡´ì¬: {self.metadata is not None}")
            if self.metadata is not None:
                logger.info(f"ë¡œì»¬ ë©”íƒ€ë°ì´í„° ê°œìˆ˜: {len(self.metadata)}")
            
            # 1. FAISS ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if hasattr(self, 'faiss_store') and self.faiss_store is not None:
                logger.info("FAISS ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ê²€ìƒ‰ ì‹œë„")
                return self._faiss_index_search(query, top_k)
            
            # 2. fallback: ë¡œì»¬ ë²¡í„° ë°°ì—´ ì‚¬ìš©
            if self.vectors is not None and self.metadata is not None:
                logger.info("ë¡œì»¬ ë²¡í„° ë°°ì—´ì„ ì‚¬ìš©í•œ ê²€ìƒ‰ ì‹œë„")
                return self._local_vector_search(query, top_k)
            
            logger.warning("ë²¡í„° ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return []
            
        except Exception as e:
            logger.error(f"FAISS ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _faiss_index_search(self, query: str, top_k: int) -> List[SearchResult]:
        """FAISS ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë²¡í„° ê²€ìƒ‰"""
        try:
            # query ê²€ì¦ ì¶”ê°€
            if not query or not isinstance(query, str):
                logger.warning("FAISS ì¸ë±ìŠ¤ ê²€ìƒ‰ ë¬´íš¨: queryê°€ ë¹„ì–´ ìˆìŒ")
                return []
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self._create_embedding(query)
            if query_embedding is None:
                logger.warning("ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return []
            
            # FAISS ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰
            logger.info(f"FAISS ì¸ë±ìŠ¤ ê²€ìƒ‰ ì‹œë„ - ì„ë² ë”© ì°¨ì›: {query_embedding.shape}")
            
            if hasattr(self.faiss_store, 'search_vector'):
                logger.info("search_vector ë©”ì„œë“œ ì‚¬ìš©")
                # FAISSStoreì˜ search_vector ë©”ì„œë“œ ì‚¬ìš© (numpy ë°°ì—´ ì§€ì›)
                search_results = self.faiss_store.search_vector(query_embedding.tolist(), top_k)
                logger.info(f"search_vector ê²°ê³¼: {len(search_results) if search_results else 0}ê°œ")
                
                # search_vector ê²°ê³¼ë¥¼ SearchResultë¡œ ë³€í™˜
                if search_results:
                    faiss_results = []
                    for result in search_results:
                        # resultì—ì„œ doc_idì™€ similarity ì¶”ì¶œ
                        doc_id = result.get('doc_id', 0)
                        similarity = result.get('similarity', 0.0)
                        
                        # chunks í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                        chunk_info = self.sqlite_store.get_chunk_info(doc_id)
                        if chunk_info:
                            search_result = SearchResult(
                                symbol_name=chunk_info.get('symbol_name', ''),
                                symbol_type=chunk_info.get('symbol_type', ''),
                                file_path=chunk_info.get('file_path', ''),
                                start_line=chunk_info.get('start_line', 0),
                                end_line=chunk_info.get('end_line', 0),
                                content=chunk_info.get('content', ''),
                                source="faiss_index",
                                similarity_score=float(similarity),
                                input_types=chunk_info.get('input_types'),
                                output_types=chunk_info.get('output_types'),
                                dependencies=chunk_info.get('dependencies'),
                                usage_examples=chunk_info.get('usage_examples')
                            )
                            faiss_results.append(search_result)
                    
                    logger.info(f"search_vector ë³€í™˜ ì™„ë£Œ: {len(faiss_results)}ê°œ ê²°ê³¼")
                    return faiss_results
                else:
                    logger.warning("search_vector ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    return []
                    
            elif hasattr(self.faiss_store, 'search'):
                logger.info("search ë©”ì„œë“œ ì‚¬ìš© (fallback)")
                # fallback: search ë©”ì„œë“œ ì‚¬ìš©
                search_results = self.faiss_store.search(query_embedding.tolist(), top_k)
                logger.info(f"search ê²°ê³¼: {len(search_results) if search_results else 0}ê°œ")
                
                # SearchResultë¡œ ë³€í™˜
                faiss_results = []
                for result in search_results:
                    # resultì—ì„œ doc_idì™€ similarity ì¶”ì¶œ
                    doc_id = result.get('doc_id', 0)
                    similarity = result.get('similarity', 0.0)
                    
                    # chunks í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
                    chunk_info = self.sqlite_store.get_chunk_info(doc_id)
                    if chunk_info:
                        search_result = SearchResult(
                            symbol_name=chunk_info.get('symbol_name', ''),
                            symbol_type=chunk_info.get('symbol_type', ''),
                            file_path=chunk_info.get('file_path', ''),
                            start_line=chunk_info.get('start_line', 0),
                            end_line=chunk_info.get('end_line', 0),
                            content=chunk_info.get('content', ''),
                            source="faiss_index",
                            similarity_score=float(similarity),
                            input_types=chunk_info.get('input_types'),
                            output_types=chunk_info.get('output_types'),
                            dependencies=chunk_info.get('dependencies'),
                            usage_examples=chunk_info.get('usage_examples')
                        )
                        faiss_results.append(search_result)
                
                logger.info(f"FAISS ì¸ë±ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(faiss_results)}ê°œ ê²°ê³¼")
                return faiss_results
            else:
                logger.warning("FAISS ì¸ë±ìŠ¤ì— search ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
                
        except Exception as e:
            logger.error(f"FAISS ì¸ë±ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _local_vector_search(self, query: str, top_k: int) -> List[SearchResult]:
        """ë¡œì»¬ ë²¡í„° ë°°ì—´ì„ ì‚¬ìš©í•œ ê²€ìƒ‰ (fallback)"""
        try:
            # query ê²€ì¦ ì¶”ê°€
            if not query or not isinstance(query, str):
                logger.warning("ë¡œì»¬ ë²¡í„° ê²€ìƒ‰ ë¬´íš¨: queryê°€ ë¹„ì–´ ìˆìŒ")
                return []
            
            # numpy ë°°ì—´ ë¹„êµ ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ ëª…ì‹œì  ì²´í¬
            if len(self.vectors) == 0 or len(self.metadata) == 0:
                logger.warning("ë²¡í„° ìŠ¤í† ì–´ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                return []
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self._create_embedding(query)
            if query_embedding is None:
                logger.warning("ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")
                return []
            
            # ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            logger.info(f"ë¡œì»¬ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì‹œì‘ - ì´ {len(self.vectors)}ê°œ ë²¡í„°")
            similarities = []
            for i, vector in enumerate(self.vectors):
                try:
                    # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if isinstance(vector, np.ndarray):
                        vector = vector.tolist()
                    similarity = self._cosine_similarity(query_embedding, vector)
                    similarities.append((i, similarity))
                    
                    # ì§„í–‰ ìƒí™© ë¡œê¹… (100ê°œë§ˆë‹¤)
                    if (i + 1) % 100 == 0:
                        logger.info(f"ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì§„í–‰: {i + 1}/{len(self.vectors)}")
                        
                except Exception as e:
                    logger.warning(f"ë²¡í„° {i} ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
                    continue
            
            if not similarities:
                logger.warning("ìœ ì‚¬ë„ ê³„ì‚° ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ ì¶”ì¶œ
            faiss_results = []
            for i, (idx, similarity) in enumerate(similarities[:top_k]):
                if idx < len(self.metadata):
                    metadata = self.metadata[idx]
                    search_result = SearchResult(
                        symbol_name=metadata.get("symbol_name", ""),
                        symbol_type=metadata.get("symbol_type", ""),
                        file_path=metadata.get("file_path", ""),
                        start_line=metadata.get("start_line", 0),
                        end_line=metadata.get("end_line", 0),
                        content=metadata.get("content", ""),
                        source="faiss_local",
                        similarity_score=float(similarity),
                        input_types=metadata.get("input_types"),
                        output_types=metadata.get("output_types"),
                        dependencies=metadata.get("dependencies"),
                        usage_examples=metadata.get("usage_examples")
                    )
                    faiss_results.append(search_result)
            
            logger.info(f"ë¡œì»¬ ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(faiss_results)}ê°œ ê²°ê³¼")
            return faiss_results
            
        except Exception as e:
            logger.error(f"ë¡œì»¬ ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _merge_search_results(self, fts_results: List[SearchResult], 
                            faiss_results: List[SearchResult], top_k: int) -> List[SearchResult]:
        """ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ë° ì¤‘ë³µ ì œê±°"""
        try:
            # ê²°ê³¼ ë³‘í•©
            all_results = fts_results + faiss_results
            
            # ì¤‘ë³µ ì œê±° (íŒŒì¼ ê²½ë¡œì™€ ì‹¬ë³¼ ì´ë¦„ ê¸°ì¤€)
            seen = set()
            unique_results = []
            
            for result in all_results:
                key = (result.file_path, result.symbol_name)
                if key not in seen:
                    seen.add(key)
                    unique_results.append(result)
            
            # ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì •ë ¬
            unique_results.sort(key=lambda x: x.similarity_score, reverse=True)
            
            # ìƒìœ„ ê²°ê³¼ ë°˜í™˜
            return unique_results[:top_k]
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì‹¤íŒ¨: {e}")
            return fts_results[:top_k] if fts_results else []
    
    def _generate_rag_answer(self, query: str, search_results: List[SearchResult]) -> str:
        """RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±"""
        try:
            if not search_results:
                return "ê´€ë ¨ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
            
            # OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‹µë³€ ìƒì„±
            if not hasattr(self, 'openai_client') or self.openai_client is None:
                return self._generate_basic_answer(query, search_results)
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(search_results)
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(query, context)
            
            # LLM í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì½”ë“œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™•ì‹ ì„ ê°€ì§€ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. ì¶”ì¸¡ì„± í‘œí˜„('ì•„ë§ˆë„', 'ì¶”ì •ë©ë‹ˆë‹¤', 'ìƒê°ë©ë‹ˆë‹¤', 'ê²ƒ ê°™ìŠµë‹ˆë‹¤')ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ë‹¨ì •ì ì´ê³  í™•ì‹  ìˆëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.1  # ë” í™•ì •ì ì¸ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤
            )
            
            answer = response.choices[0].message.content
            logger.info("RAG ë‹µë³€ ìƒì„± ì™„ë£Œ")
            return answer
            
        except Exception as e:
            logger.error(f"RAG ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def _build_context(self, search_results: List[SearchResult]) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¡œë¶€í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìœ„ì¹˜, ì‚¬ìš©ë²•, í™œìš© ì •ë³´ í¬í•¨)"""
        context_parts = []
        
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì‹œì‘: {len(search_results)}ê°œ ê²€ìƒ‰ ê²°ê³¼")
        
        for i, result in enumerate(search_results, 1):
            logger.info(f"ê²°ê³¼ {i} ë””ë²„ê¹…: file_path={result.file_path}, symbol_name={result.symbol_name}, content_length={len(result.content) if result.content else 0}")
            
            context_part = f"""
            [ì°¸ì¡° {i}]
            ìœ„ì¹˜: {result.file_path}ì˜ {result.start_line}-{result.end_line} ë¼ì¸
            ì‹¬ë³¼: {result.symbol_name} ({result.symbol_type})
            
            ì½”ë“œ ë‚´ìš©:
            {result.content}
            """
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ê°€ ìˆìœ¼ë©´ í¬í•¨
            if result.input_types or result.output_types or result.dependencies or result.usage_examples:
                context_part += "\nì¶”ê°€ ì •ë³´:\n"
                
                if result.input_types:
                    context_part += f"ì…ë ¥: {result.input_types}\n"
                if result.output_types:
                    context_part += f"ì¶œë ¥: {result.output_types}\n"
                if result.dependencies:
                    deps = ", ".join(result.dependencies) if isinstance(result.dependencies, list) else str(result.dependencies)
                    context_part += f"ì˜ì¡´ì„±: {deps}\n"
                if result.usage_examples:
                    context_part += f"ì‚¬ìš© ì˜ˆì‹œ: {result.usage_examples}\n"
            
            context_parts.append(context_part)
        
        return "\n".join(context_parts)
    
    def _build_prompt(self, query: str, context: str) -> str:
        """í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ììœ ë¡œìš´ ëŒ€í™”ì™€ ê¹Šì´ ìˆëŠ” ë¶„ì„ ì§€ì›)"""
        return f"""
        ì‚¬ìš©ì ì§ˆë¬¸: {query}
        
        ë‹¤ìŒ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ì¡°í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”:
        {context}
        
        ë‹µë³€ ìš”êµ¬ì‚¬í•­:
        1. ì œê³µëœ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í™•ì‹ ì„ ê°€ì§€ê³  ë‹µë³€í•˜ì„¸ìš”
        2. ì¶”ì¸¡ì„± í‘œí˜„('ì•„ë§ˆë„', 'ì¶”ì •ë©ë‹ˆë‹¤', 'ìƒê°ë©ë‹ˆë‹¤', 'ê²ƒ ê°™ìŠµë‹ˆë‹¤', 'ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤')ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
        3. ë‹¨ì •ì ì´ê³  ëª…í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš” ('ì´ ì½”ë“œëŠ” ~í•©ë‹ˆë‹¤', 'ì´ í•¨ìˆ˜ëŠ” ~ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤', 'ì´ê²ƒì€ ~ì…ë‹ˆë‹¤')
        4. ì½”ë“œì˜ ìœ„ì¹˜, ì‚¬ìš©ë²•, ê¸°ëŠ¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”
        5. í•„ìš”í•œ ê²½ìš° ì¶”ê°€ì ì¸ ì„¸ë¶€ì‚¬í•­ì´ë‚˜ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”
        6. ì „ë¬¸ê°€ë¡œì„œ í™•ì‹ ì— ì°¬ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
        7. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
        """
    
    def _create_embedding(self, text: str) -> Optional[np.ndarray]:
        """í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
            embedding_model = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT", "text-embedding-3-large")
            
            # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
            response = self.openai_client.embeddings.create(
                model=embedding_model,
                input=text
            )
            
            embedding_array = np.array(response.data[0].embedding)
            logger.info(f"ì„ë² ë”© ìƒì„± ì„±ê³µ: ì°¨ì›={embedding_array.shape}")
            
            return embedding_array
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            logger.info("ì„ë² ë”© ì‹¤íŒ¨ë¡œ ì¸í•´ ë²¡í„° ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            # ì„ë² ë”© ì‹¤íŒ¨ ì‹œ None ë°˜í™˜í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ ê±´ë„ˆë›°ê¸°
            return None
    
    def _cosine_similarity(self, vec1, vec2) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (numpy ë°°ì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ ì§€ì›)"""
        try:
            # numpy ë°°ì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            vec1 = np.asarray(vec1, dtype=np.float64)
            vec2 = np.asarray(vec2, dtype=np.float64)
            
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            # numpy ë°°ì—´ ë¹„êµ ëŒ€ì‹  float ë¹„êµ ì‚¬ìš©
            if float(norm1) == 0.0 or float(norm2) == 0.0:
                return 0.0
            
            return float(dot_product / (norm1 * norm2))
        except Exception as e:
            logger.error(f"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _calculate_confidence(self, search_results: List[SearchResult]) -> float:
        """ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not search_results:
            return 0.0
        
        # ê²€ìƒ‰ ê²°ê³¼ì˜ í‰ê·  ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ì‹ ë¢°ë„ ê³„ì‚°
        avg_similarity = sum(result.similarity_score for result in search_results) / len(search_results)
        return min(avg_similarity, 1.0)
    
    def get_search_stats(self) -> Dict[str, Any]:
        """ê²€ìƒ‰ í†µê³„ ì •ë³´ ë°˜í™˜"""
        try:
            stats = {
                "sqlite_available": hasattr(self, 'sqlite_store'),
                "openai_available": hasattr(self, 'openai_client'),
                "vector_search": {
                    "sqlite_embeddings": {
                        "loaded": self.vectors is not None and self.metadata is not None,
                        "total_vectors": len(self.vectors) if self.vectors is not None else 0,
                        "total_metadata": len(self.metadata) if self.metadata is not None else 0
                    },
                    "faiss_index": {
                        "loaded": hasattr(self, 'faiss_store') and self.faiss_store is not None,
                        "index_path": str(self.artifacts_dir / "faiss.index") if hasattr(self, 'artifacts_dir') else None,
                        "index_exists": (self.artifacts_dir / "faiss.index").exists() if hasattr(self, 'artifacts_dir') else False
                    }
                }
            }
            
            # SQLite í†µê³„ ì¶”ê°€
            if hasattr(self, 'sqlite_store'):
                try:
                    db_stats = self.sqlite_store.get_database_stats()
                    stats["sqlite_stats"] = db_stats
                except Exception as e:
                    stats["sqlite_stats"] = {"error": str(e)}
            
            return stats
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}
    
    def _get_available_artifacts(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ ëª©ë¡ì„ ë™ì ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ ìƒì„±"""
        try:
            from tools.insightgen_tools import get_artifact_summary
            
            artifact_summary = get_artifact_summary.invoke({"data_dir": str(self.data_dir)})
            
            if "error" in artifact_summary or not artifact_summary.get("summaries"):
                return "   - ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤. InsightGenì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
            
            artifact_lines = []
            for summary in artifact_summary["summaries"]:
                name = summary["name"]
                preview = summary["preview"]
                # í”„ë¦¬ë·°ì—ì„œ ì²« ë²ˆì§¸ ì¤„ì´ë‚˜ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
                description = preview.split('\n')[0][:100] + "..."
                artifact_lines.append(f"   - {name}: {description}")
            
            return "\n".join(artifact_lines)
            
        except Exception as e:
            logger.warning(f"ì‚°ì¶œë¬¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return "   - ì‚°ì¶œë¬¼ ì¡°íšŒ ì‹¤íŒ¨ (InsightGenì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”)"

    def _get_first_available_artifact(self) -> Optional[str]:
        """ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ íŒŒì¼ëª… ë°˜í™˜"""
        try:
            from tools.insightgen_tools import list_artifacts
            
            artifacts_info = list_artifacts.invoke({"data_dir": str(self.data_dir)})
            
            # artifacts_infoê°€ Noneì¸ ê²½ìš° ì²˜ë¦¬
            if artifacts_info is None:
                logger.warning("artifacts_infoê°€ Noneì…ë‹ˆë‹¤")
                return None
            
            if "error" not in artifacts_info and artifacts_info.get("artifacts"):
                artifacts = artifacts_info.get("artifacts", [])
                if not artifacts:
                    logger.warning("artifacts ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
                    return None
                
                # MD íŒŒì¼ ìš°ì„ , ìˆœì„œëŒ€ë¡œ ì •ë ¬ëœ ì²« ë²ˆì§¸ íŒŒì¼
                md_files = []
                for artifact in artifacts:
                    if artifact and isinstance(artifact, dict) and artifact.get("name", "").endswith('.md'):
                        md_files.append(artifact["name"])
                
                if md_files:
                    return md_files[0]
                
                # MD íŒŒì¼ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ íŒŒì¼
                first_artifact = artifacts[0]
                if first_artifact and isinstance(first_artifact, dict):
                    return first_artifact.get("name")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ì´ ì—†ìœ¼ë©´ None
            return None
            
        except Exception as e:
            logger.warning(f"ì²« ë²ˆì§¸ ì‚°ì¶œë¬¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def _analyze_query_and_select_tools(self, query: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """AI ê¸°ë°˜ ì§ˆë¬¸ ë¶„ì„ ë° ë„êµ¬ ì„ íƒ"""
        try:
            logger.info(f"ğŸ¤– LLM ì§ˆë¬¸ ë¶„ì„ ì‹œì‘: '{query}'")
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context_str = ""
            if context:
                context_parts = []
                
                # ìµœê·¼ ëŒ€í™” ë‚´ìš©
                if context.get("recent_conversations"):
                    recent_queries = [conv["query"] for conv in context["recent_conversations"][-3:]]
                    context_parts.append(f"ìµœê·¼ ì§ˆë¬¸ë“¤: {', '.join(recent_queries)}")
                
                # ì–¸ê¸‰ëœ ì‹¬ë³¼ë“¤
                if context.get("mentioned_symbols"):
                    context_parts.append(f"ì´ì „ì— ì–¸ê¸‰ëœ ì‹¬ë³¼ë“¤: {', '.join(context['mentioned_symbols'][:5])}")
                
                # ì–¸ê¸‰ëœ íŒŒì¼ë“¤
                if context.get("mentioned_files"):
                    context_parts.append(f"ì´ì „ì— ì–¸ê¸‰ëœ íŒŒì¼ë“¤: {', '.join(context['mentioned_files'][:3])}")
                
                context_str = "\n".join(context_parts) if context_parts else ""
            
            # ì§ˆë¬¸ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
            classification_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:

ì§ˆë¬¸: {query}

{context_str}

ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:
1. get_artifact: í”„ë¡œì íŠ¸ ê°œìš”, ì „ì²´ êµ¬ì¡°, íë¦„ ë“± ì „ë°˜ì  ì„¤ëª…
{self._get_available_artifacts()}
2. search_symbols_fts/semantic: íŠ¹ì • ì‹¬ë³¼/í‚¤ì›Œë“œ ê²€ìƒ‰
3. get_symbol/get_chunks_by_symbol: ì‹¬ë³¼/ì²­í¬ ì„¸ë¶€ ì •ë³´
4. get_calls_from/get_calls_to: í˜¸ì¶œ ê´€ê³„ ë¶„ì„
5. analyze_file_llm/analyze_symbol_llm: LLM ê¸°ë°˜ ì½”ë“œ ë¶„ì„
6. get_source_code: íŒŒì¼ ê²½ë¡œì™€ ë¼ì¸ ë²”ìœ„ë¡œ ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
7. analyze_source_code_with_llm: ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ LLMìœ¼ë¡œ ë¶„ì„
8. get_function_source: í•¨ìˆ˜/í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œ ê²€ìƒ‰

ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì˜ ë§¥ë½ì„ íŒŒì•…í•˜ê³  ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”. 

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "query_type": "overview|specific",
    "selected_tools": ["tool1", "tool2"],
    "reasoning": "ì„ íƒ ì´ìœ  (ì»¨í…ìŠ¤íŠ¸ ê³ ë ¤ì‚¬í•­ í¬í•¨)",
    "artifact_name": "ì ì ˆí•œ ì‚°ì¶œë¬¼ íŒŒì¼ëª… (ìœ„ ëª©ë¡ì—ì„œ ì„ íƒ)"
}}
"""
            
            # LLMìœ¼ë¡œ ë„êµ¬ ì„ íƒ
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì½”ë“œ ë¶„ì„ ë„êµ¬ ì„ íƒ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì •í™•íˆ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ë„êµ¬ë¥¼ ì„ íƒí•˜ì„¸ìš”."},
                    {"role": "user", "content": classification_prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            llm_response = response.choices[0].message.content
            logger.info(f"ğŸ¤– LLM ì‘ë‹µ: {llm_response[:200]}...")
            
            result = self._parse_tool_selection(llm_response)
            logger.info(f"âœ… ë„êµ¬ ì„ íƒ ì™„ë£Œ: {result['query_type']} -> {result['selected_tools']}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì§ˆë¬¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ ê¸°ë³¸ ê²€ìƒ‰ ë„êµ¬ë¡œ fallback")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©
            return {
                "query_type": "specific",
                "selected_tools": ["search_symbols_fts", "search_symbols_semantic"],
                "reasoning": "ë¶„ì„ ì‹¤íŒ¨ë¡œ ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš©",
                "artifact_name": None
            }
    
    def _parse_tool_selection(self, llm_response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ë„êµ¬ ì„ íƒ ì •ë³´ ì¶”ì¶œ"""
        # ê¸°ë³¸ê°’ ì •ì˜
        default_result = {
            "query_type": "specific",
            "selected_tools": ["search_symbols_fts"],
            "reasoning": "ê¸°ë³¸ ê²€ìƒ‰ ì‚¬ìš©",
            "artifact_name": None
        }
        
        try:
            import json
            import re
            
            logger.info("ğŸ” LLM ì‘ë‹µ íŒŒì‹± ì‹œì‘")
            
            # llm_responseê°€ Noneì´ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
            if not llm_response or not isinstance(llm_response, str):
                logger.warning("âŒ LLM ì‘ë‹µì´ ë¹„ì–´ìˆê±°ë‚˜ ë¬¸ìì—´ì´ ì•„ë‹˜")
                return default_result
            
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                try:
                    data = json.loads(json_match.group())
                    logger.info(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {data}")
                    
                    # dataê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
                    if not data or not isinstance(data, dict):
                        logger.warning("âŒ íŒŒì‹±ëœ ë°ì´í„°ê°€ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ ì•„ë‹˜")
                        return default_result
                    
                    return {
                        "query_type": data.get("query_type", "specific"),
                        "selected_tools": data.get("selected_tools", ["search_symbols_fts"]),
                        "reasoning": data.get("reasoning", ""),
                        "artifact_name": data.get("artifact_name", self._get_first_available_artifact())
                    }
                except json.JSONDecodeError as e:
                    logger.warning(f"âŒ JSON ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                    return default_result
            else:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
                logger.warning("âŒ JSON íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš©")
                return default_result
                
        except Exception as e:
            logger.error(f"âŒ ë„êµ¬ ì„ íƒ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return default_result
    
    def _handle_overview_query(self, query: str, tool_selection: Dict[str, Any]) -> ChatResponse:
        """ê°œìš”/ì „ë°˜ì  ì§ˆë¬¸ ì²˜ë¦¬"""
        try:
            # get_artifact ë„êµ¬ ì‚¬ìš©
            from tools.insightgen_tools import get_artifact
            
            artifact_name = tool_selection.get("artifact_name") or self._get_first_available_artifact()
            logger.info(f"ğŸ“ ì‚°ì¶œë¬¼ ë¡œë“œ ì‹œì‘: {artifact_name}")
            
            artifact_result = get_artifact.invoke({
                "artifact_name": artifact_name,
                "data_dir": str(self.data_dir)
            })
            
            if "error" in artifact_result:
                # ì‚°ì¶œë¬¼ì´ ì—†ìœ¼ë©´ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ ëª©ë¡ í™•ì¸
                logger.warning(f"âŒ ì‚°ì¶œë¬¼ ë¡œë“œ ì‹¤íŒ¨: {artifact_result['error']}")
                
                # ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ ëª©ë¡ ì¡°íšŒ
                from tools.insightgen_tools import list_artifacts
                available_artifacts = list_artifacts.invoke({"data_dir": str(self.data_dir)})
                
                if "artifacts" in available_artifacts and available_artifacts["artifacts"]:
                    # ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ ì‚¬ìš©
                    first_artifact = available_artifacts["artifacts"][0]["name"]
                    logger.info(f"ğŸ”„ ëŒ€ì²´ ì‚°ì¶œë¬¼ ì‚¬ìš©: {first_artifact}")
                    
                    artifact_result = get_artifact.invoke({
                        "artifact_name": first_artifact,
                        "data_dir": str(self.data_dir)
                    })
                    
                    if "error" in artifact_result:
                        logger.warning(f"âŒ ëŒ€ì²´ ì‚°ì¶œë¬¼ë„ ì‹¤íŒ¨: {artifact_result['error']}")
                        logger.info("ğŸ”„ ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback")
                        return self._handle_specific_query(query, tool_selection, 10)
                else:
                    logger.warning("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤")
                    logger.info("ğŸ”„ ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback")
                    return self._handle_specific_query(query, tool_selection, 10)
            
            # ì‚°ì¶œë¬¼ ë¡œë“œ ì„±ê³µ ë¡œê¹…
            artifact_content = artifact_result.get("content", "")
            logger.info(f"âœ… ì‚°ì¶œë¬¼ ë¡œë“œ ì„±ê³µ: {len(artifact_content)}ì")
            logger.info(f"ğŸ“„ ì‚°ì¶œë¬¼ ê²½ë¡œ: {artifact_result.get('path', 'unknown')}")
            
            # ì‚¬ìš©ì ì§ˆë¬¸ì— ë§ëŠ” ë‹µë³€ ìƒì„±
            logger.info("ğŸ¤– LLM ê¸°ë°˜ ê°œìš” ë‹µë³€ ìƒì„± ì‹œì‘")
            answer = self._generate_overview_answer(query, artifact_content)
            logger.info("âœ… ê°œìš” ë‹µë³€ ìƒì„± ì™„ë£Œ")
            
            # SearchResult í˜•íƒœë¡œ ë³€í™˜
            evidence = [SearchResult(
                symbol_name="í”„ë¡œì íŠ¸ ê°œìš”",
                symbol_type="document",
                file_path=artifact_result.get("path", ""),
                start_line=0,
                end_line=0,
                content=artifact_content[:500] + "..." if len(artifact_content) > 500 else artifact_content,
                source="artifact",
                similarity_score=1.0
            )]
            
            return ChatResponse(
                answer=answer,
                evidence=evidence,
                confidence=0.9
            )
            
        except Exception as e:
            logger.error(f"ê°œìš” ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ fallback
            return self._handle_specific_query(query, tool_selection, 10)
    
    def _handle_specific_query(self, query: str, tool_selection: Dict[str, Any], top_k: int) -> ChatResponse:
        """íŠ¹ì • ì½”ë“œ ì§ˆë¬¸ ì²˜ë¦¬"""
        try:
            logger.info(f"ğŸ” íŠ¹ì • ì½”ë“œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘: {tool_selection.get('selected_tools', [])}")
            
            # ìƒˆë¡œìš´ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ í™•ì¸
            selected_tools = tool_selection.get("selected_tools", [])
            
            # ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œ ì ‘ê·¼ ë„êµ¬ë“¤ì´ ì„ íƒëœ ê²½ìš°
            if any(tool in selected_tools for tool in ["get_source_code", "analyze_source_code_with_llm", "get_function_source"]):
                logger.info("ğŸ”§ ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œ ì ‘ê·¼ ë„êµ¬ ì‚¬ìš©")
                return self._handle_source_code_query(query, tool_selection, top_k)
            
            # ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰
            logger.info(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰: top_k={top_k}")
            search_results = self._hybrid_search(query, top_k)
            
            if not search_results:
                logger.warning("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return ChatResponse(
                    answer="ê´€ë ¨ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.",
                    evidence=[],
                    confidence=0.0
                )
            
            logger.info(f"âœ… ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ")
            
            # RAG ê¸°ë°˜ ë‹µë³€ ìƒì„±
            logger.info("ğŸ¤– RAG ê¸°ë°˜ ë‹µë³€ ìƒì„± ì‹œì‘")
            answer = self._generate_rag_answer(query, search_results)
            logger.info("âœ… RAG ë‹µë³€ ìƒì„± ì™„ë£Œ")
            
            confidence = self._calculate_confidence(search_results)
            logger.info(f"ğŸ“Š ì‘ë‹µ ì‹ ë¢°ë„: {confidence:.2f}")
            
            return ChatResponse(
                answer=answer,
                evidence=search_results,
                confidence=confidence
            )
            
        except Exception as e:
            logger.error(f"íŠ¹ì • ì½”ë“œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return ChatResponse(
                answer=f"ì½”ë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                evidence=[],
                confidence=0.0
            )
    
    def _handle_source_code_query(self, query: str, tool_selection: Dict[str, Any], top_k: int) -> ChatResponse:
        """ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œ ì ‘ê·¼ ë„êµ¬ë¥¼ ì‚¬ìš©í•œ ì§ˆë¬¸ ì²˜ë¦¬"""
        try:
            # ì•ˆì „í•œ import ì²˜ë¦¬
            try:
                from tools.llm_tools import get_function_source, analyze_source_code_with_llm, get_source_code
                logger.info("âœ… ì†ŒìŠ¤ì½”ë“œ ë„êµ¬ import ì„±ê³µ")
            except ImportError as e:
                logger.error(f"âŒ ì†ŒìŠ¤ì½”ë“œ ë„êµ¬ import ì‹¤íŒ¨: {e}")
                # fallback to basic search
                search_results = self._hybrid_search(query, top_k)
                answer = self._generate_rag_answer(query, search_results)
                return ChatResponse(answer=answer, evidence=search_results, confidence=0.5)
            
            # tool_selection ì•ˆì „ ì²˜ë¦¬
            if not tool_selection or not isinstance(tool_selection, dict):
                logger.warning("tool_selectionì´ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹˜")
                tool_selection = {"selected_tools": []}
            
            selected_tools = tool_selection.get("selected_tools", [])
            logger.info(f"ğŸ”§ ì†ŒìŠ¤ì½”ë“œ ë„êµ¬ ì‚¬ìš©: {selected_tools}")
            
            # í•¨ìˆ˜/í´ë˜ìŠ¤ ì´ë¦„ì„ ì§ˆë¬¸ì—ì„œ ì¶”ì¶œ
            function_name = self._extract_function_name_from_query(query)
            file_path = self._extract_file_path_from_query(query)
            
            evidence = []
            analysis_results = []
            
            # get_function_source ë„êµ¬ ì‚¬ìš©
            if "get_function_source" in selected_tools and function_name:
                logger.info(f"ğŸ” í•¨ìˆ˜ ì†ŒìŠ¤ì½”ë“œ ê²€ìƒ‰: {function_name}")
                
                try:
                    source_result = get_function_source(
                        symbol_name=function_name,
                        file_path=file_path,
                        data_dir=str(self.data_dir)
                    )
                    
                    # None ì²´í¬ ì¶”ê°€
                    if source_result is None:
                        logger.warning("get_function_source ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤")
                        source_result = {"success": False, "error": "ê²°ê³¼ê°€ None"}
                    
                    if source_result.get("success") and source_result.get("results"):
                        for result in source_result["results"]:
                            if "error" not in result:
                                try:
                                    # line_range ì•ˆì „ ì²˜ë¦¬
                                    line_range = result.get("line_range", "1-1")
                                    if "-" in line_range:
                                        start_line = int(line_range.split("-")[0])
                                        end_line = int(line_range.split("-")[1])
                                    else:
                                        start_line = end_line = int(line_range)
                                    
                                    # SearchResult í˜•íƒœë¡œ ë³€í™˜
                                    search_result = SearchResult(
                                        symbol_name=result.get("symbol_name", "unknown"),
                                        symbol_type=result.get("symbol_type", "unknown"),
                                        file_path=result.get("file_path", ""),
                                        start_line=start_line,
                                        end_line=end_line,
                                        content=result.get("source_code", ""),
                                        source="source_code_tool",
                                        similarity_score=1.0
                                    )
                                    evidence.append(search_result)
                                    analysis_results.append(result)
                                except Exception as e:
                                    logger.warning(f"SearchResult ë³€í™˜ ì‹¤íŒ¨: {e}")
                                    continue
                    else:
                        logger.warning(f"í•¨ìˆ˜ ì†ŒìŠ¤ì½”ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {source_result}")
                        
                except Exception as e:
                    logger.error(f"get_function_source í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            
            # analyze_source_code_with_llm ë„êµ¬ ì‚¬ìš©
            if "analyze_source_code_with_llm" in selected_tools:
                logger.info(f"ğŸ¤– ì†ŒìŠ¤ì½”ë“œ LLM ë¶„ì„ ìˆ˜í–‰")
                
                # ì´ë¯¸ ì°¾ì€ ì†ŒìŠ¤ì½”ë“œê°€ ìˆìœ¼ë©´ ë¶„ì„
                for result in analysis_results:
                    try:
                        # line_range ì•ˆì „ ì²˜ë¦¬
                        line_range = result.get("line_range", "1-1")
                        if "-" in line_range:
                            start_line = int(line_range.split("-")[0])
                            end_line = int(line_range.split("-")[1])
                        else:
                            start_line = end_line = int(line_range)
                            
                        analysis = analyze_source_code_with_llm(
                            file_path=result.get("file_path", ""),
                            start_line=start_line,
                            end_line=end_line,
                            question=query,
                            data_dir=str(self.data_dir)
                        )
                        
                        # None ì²´í¬ ì¶”ê°€
                        if analysis is None:
                            logger.warning("analyze_source_code_with_llm ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤")
                            continue
                        
                        if analysis.get("success"):
                            # ë¶„ì„ ê²°ê³¼ë¥¼ SearchResultì— ì¶”ê°€
                            for i, ev in enumerate(evidence):
                                if ev.file_path == result.get("file_path", ""):
                                    evidence[i] = SearchResult(
                                        symbol_name=ev.symbol_name,
                                        symbol_type=ev.symbol_type,
                                        file_path=ev.file_path,
                                        start_line=ev.start_line,
                                        end_line=ev.end_line,
                                        content=ev.content,
                                        source="llm_analyzed_source",
                                        similarity_score=1.0,
                                        usage_examples=analysis.get("analysis", "")
                                    )
                                    break
                    except Exception as e:
                        logger.error(f"ì†ŒìŠ¤ì½”ë“œ LLM ë¶„ì„ ì‹¤íŒ¨: {e}")
                        continue
            
            # get_source_code ë„êµ¬ ì§ì ‘ ì‚¬ìš© (íŒŒì¼ ê²½ë¡œê°€ ëª…ì‹œëœ ê²½ìš°)
            if "get_source_code" in selected_tools and file_path:
                logger.info(f"ğŸ“ íŒŒì¼ ì†ŒìŠ¤ì½”ë“œ ì§ì ‘ ì ‘ê·¼: {file_path}")
                
                try:
                    source_result = get_source_code(
                        file_path=file_path,
                        data_dir=str(self.data_dir)
                    )
                    
                    # None ì²´í¬ ì¶”ê°€
                    if source_result is None:
                        logger.warning("get_source_code ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤")
                        source_result = {"success": False, "error": "ê²°ê³¼ê°€ None"}
                    
                    if source_result.get("success"):
                        search_result = SearchResult(
                            symbol_name="íŒŒì¼ ì „ì²´",
                            symbol_type="file",
                            file_path=source_result.get("file_path", file_path),
                            start_line=source_result.get("start_line", 1),
                            end_line=source_result.get("end_line", 1),
                            content=source_result.get("source_code", ""),
                            source="direct_file_access",
                            similarity_score=1.0
                        )
                        evidence.append(search_result)
                    else:
                        logger.warning(f"íŒŒì¼ ì†ŒìŠ¤ì½”ë“œ ì§ì ‘ ì ‘ê·¼ ì‹¤íŒ¨: {source_result}")
                        
                except Exception as e:
                    logger.error(f"get_source_code í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            
            # fallback: ê¸°ë³¸ ê²€ìƒ‰ë„ ìˆ˜í–‰
            if not evidence:
                logger.info("ğŸ”„ ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ ì°¾ì§€ ëª»í•¨, ê¸°ë³¸ ê²€ìƒ‰ ìˆ˜í–‰")
                search_results = self._hybrid_search(query, top_k)
                evidence.extend(search_results)
            
            if not evidence:
                return ChatResponse(
                    answer="ìš”ì²­í•˜ì‹  ì†ŒìŠ¤ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•¨ìˆ˜/í´ë˜ìŠ¤ ì´ë¦„ì´ë‚˜ íŒŒì¼ ê²½ë¡œë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œí•´ì£¼ì„¸ìš”.",
                    evidence=[],
                    confidence=0.0
                )
            
            # ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ í¬í•¨í•œ í–¥ìƒëœ RAG ë‹µë³€ ìƒì„±
            logger.info("ğŸ¤– ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œ ê¸°ë°˜ RAG ë‹µë³€ ìƒì„±")
            answer = self._generate_enhanced_rag_answer(query, evidence, analysis_results)
            
            return ChatResponse(
                answer=answer,
                evidence=evidence,
                confidence=0.95
            )
            
        except Exception as e:
            logger.error(f"ì†ŒìŠ¤ì½”ë“œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # fallback to basic search
            search_results = self._hybrid_search(query, top_k)
            answer = self._generate_rag_answer(query, search_results)
            return ChatResponse(
                answer=answer,
                evidence=search_results,
                confidence=0.5
            )
    
    def _extract_function_name_from_query(self, query: str) -> Optional[str]:
        """ì§ˆë¬¸ì—ì„œ í•¨ìˆ˜/í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ"""
        import re
        
        # ì¼ë°˜ì ì¸ íŒ¨í„´ë“¤ë¡œ í•¨ìˆ˜ëª… ì¶”ì¶œ ì‹œë„
        patterns = [
            r'([a-zA-Z_][a-zA-Z0-9_]*)\s*(?:í•¨ìˆ˜|ë©”ì„œë“œ|í´ë˜ìŠ¤)',
            r'([a-zA-Z_][a-zA-Z0-9_]*)\(\)',
            r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)',
            r'class\s+([a-zA-Z_][a-zA-Z0-9_]*)',
            r'([a-zA-Z_][a-zA-Z0-9_]*)\s*(?:ì—\s*ëŒ€í•´|ì—ì„œ|ë¥¼|ì„|ì˜)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query)
            if match:
                function_name = match.group(1)
                # ì¼ë°˜ì ì¸ í‚¤ì›Œë“œë“¤ì€ ì œì™¸
                if function_name not in ['def', 'class', 'import', 'from', 'return', 'if', 'for', 'while']:
                    logger.info(f"ì¶”ì¶œëœ í•¨ìˆ˜ëª…: {function_name}")
                    return function_name
        
        return None
    
    def _extract_file_path_from_query(self, query: str) -> Optional[str]:
        """ì§ˆë¬¸ì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ"""
        import re
        
        # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ë“¤
        patterns = [
            r'([a-zA-Z0-9_./\\]+\.py)',
            r'([a-zA-Z0-9_./\\]+\.java)',
            r'([a-zA-Z0-9_./\\]+\.cpp)',
            r'([a-zA-Z0-9_./\\]+\.c)',
            r'([a-zA-Z0-9_./\\]+\.h)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, query)
            if match:
                file_path = match.group(1)
                logger.info(f"ì¶”ì¶œëœ íŒŒì¼ ê²½ë¡œ: {file_path}")
                return file_path
        
        return None
    
    def _generate_enhanced_rag_answer(self, query: str, evidence: List[SearchResult], analysis_results: List[Dict]) -> str:
        """ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ í¬í•¨í•œ í–¥ìƒëœ RAG ë‹µë³€ ìƒì„±"""
        try:
            # evidenceì™€ analysis_resultsê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸
            if evidence is None:
                evidence = []
            if analysis_results is None:
                analysis_results = []
                
            # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = self._build_context(evidence)
            
            # ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            analysis_context = ""
            if analysis_results:
                analysis_parts = []
                for analysis in analysis_results:
                    if analysis and isinstance(analysis, dict) and analysis.get("analysis"):
                        analysis_parts.append(f"""
[LLM ë¶„ì„ ê²°ê³¼]
íŒŒì¼: {analysis.get('file_path', 'unknown')}
ë¼ì¸: {analysis.get('line_range', 'unknown')}
ë¶„ì„ ë‚´ìš©:
{analysis['analysis']}
""")
                analysis_context = "\n".join(analysis_parts)
            
            # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            enhanced_prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {query}

ë‹¤ìŒì€ ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œì™€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤:

{context}

{analysis_context}

ë‹µë³€ ìš”êµ¬ì‚¬í•­:
1. ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ í™•ì‹ ì„ ê°€ì§€ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
2. ì¶”ì¸¡ì„± í‘œí˜„('ì•„ë§ˆë„', 'ì¶”ì •ë©ë‹ˆë‹¤', 'ìƒê°ë©ë‹ˆë‹¤', 'ê²ƒ ê°™ìŠµë‹ˆë‹¤')ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. ë‹¨ì •ì ì´ê³  ëª…í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš” ('ì´ í•¨ìˆ˜ëŠ” ~ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤', 'ì´ ì½”ë“œëŠ” ~í•©ë‹ˆë‹¤')
4. ì½”ë“œì˜ êµ¬ì²´ì ì¸ ë™ì‘ê³¼ êµ¬í˜„ ë‚´ìš©ì„ í™•ì‹  ìˆê²Œ ì„¤ëª…í•˜ì„¸ìš”
5. í•¨ìˆ˜/í´ë˜ìŠ¤ì˜ ì—­í• ê³¼ ëª©ì ì„ ëª…í™•íˆ ë‹¨ì–¸í•˜ì„¸ìš”
6. ì½”ë“œì˜ ì…ì¶œë ¥, ë§¤ê°œë³€ìˆ˜, ë°˜í™˜ê°’ ë“± ìƒì„¸ ì •ë³´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”
7. ì‹¤ì œ ì½”ë“œ ì˜ˆì‹œë‚˜ ì¤‘ìš”í•œ ì½”ë“œ ë¼ì¸ì„ í™•ì‹  ìˆê²Œ ì¸ìš©í•˜ì„¸ìš”
8. ì½”ë“œì˜ íë¦„ê³¼ ë¡œì§ì„ ë‹¨ê³„ë³„ë¡œ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”
9. ì „ë¬¸ê°€ë¡œì„œ í™•ì‹ ì— ì°¬ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
10. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”

ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ ë¶„ì„í–ˆìœ¼ë¯€ë¡œ ì¶”ì¸¡ ì—†ì´ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""
            
            # LLM í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì‹¤ì œ ì½”ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ í™•ì‹ ì„ ê°€ì§€ê³  ëª…í™•í•˜ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. ì¶”ì¸¡ì„± í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ê³  ë‹¨ì •ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."},
                    {"role": "user", "content": enhanced_prompt}
                ],
                max_tokens=2000,
                temperature=0.1  # ë” í™•ì •ì ì¸ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"í–¥ìƒëœ RAG ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # fallback to basic RAG
            return self._generate_rag_answer(query, evidence)
    
    def _generate_overview_answer(self, query: str, artifact_content: str) -> str:
        """ì‚°ì¶œë¬¼ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°œìš” ë‹µë³€ ìƒì„±"""
        try:
            prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: {query}

ë‹¤ìŒì€ í”„ë¡œì íŠ¸ ê°œìš” ë¬¸ì„œì…ë‹ˆë‹¤:
{artifact_content}

ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”:
1. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í™•ì‹ ì„ ê°€ì§€ê³  ë‹µë³€í•˜ì„¸ìš”
2. ì¶”ì¸¡ì„± í‘œí˜„('ì•„ë§ˆë„', 'ì¶”ì •ë©ë‹ˆë‹¤', 'ìƒê°ë©ë‹ˆë‹¤', 'ê²ƒ ê°™ìŠµë‹ˆë‹¤')ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. ë‹¨ì •ì ì´ê³  ëª…í™•í•œ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš” ('ì´ í”„ë¡œì íŠ¸ëŠ” ~ì…ë‹ˆë‹¤', 'ì‹œìŠ¤í…œì€ ~ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤')
4. ì§ˆë¬¸ì˜ ì˜ë„ì— ë§ëŠ” ì •ë³´ë¥¼ ì°¾ì•„ì„œ í™•ì‹  ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”
5. ë¶ˆí•„ìš”í•œ ìˆ˜ì‚¬ëŠ” ë°°ì œí•˜ê³  ì‚¬ì‹¤ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
6. ì „ë¬¸ê°€ë¡œì„œ í™•ì‹ ì— ì°¬ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
7. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•˜ì„¸ìš”
8. ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ "í•´ë‹¹ ì •ë³´ê°€ ë¬¸ì„œì— í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•íˆ ë‹µë³€í•˜ì„¸ìš”
"""
            
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì½”ë“œë² ì´ìŠ¤ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ê°œìš” ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í™•ì‹ ì„ ê°€ì§€ê³  ëª…í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. ì¶”ì¸¡ì„± í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ë§ê³  ë‹¨ì •ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.1  # ë” í™•ì •ì ì¸ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ê°œìš” ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # LLM ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë‹µë³€
            return f"í”„ë¡œì íŠ¸ ê°œìš” ì •ë³´ë¥¼ ì°¾ì•˜ì§€ë§Œ, êµ¬ì²´ì ì¸ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›ë³¸ ë¬¸ì„œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n\n{artifact_content[:300]}..."
