"""
ê°„ë‹¨í•œ AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ - ì§ˆë¬¸ê³¼ ë‹µë³€ë§Œìœ¼ë¡œ í‰ê°€
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass
import json
import re

logger = logging.getLogger(__name__)

@dataclass
class SimpleEvaluation:
    """ê°„ë‹¨í•œ í‰ê°€ ê²°ê³¼"""
    score: float  # 0-100 ì ìˆ˜
    is_sufficient: bool  # ì¶©ë¶„í•œ ë‹µë³€ì¸ì§€
    missing_parts: List[str]  # ë¶€ì¡±í•œ ë¶€ë¶„ë“¤
    feedback: str  # ê°œì„  í”¼ë“œë°±
    confidence: float  # í‰ê°€ ì‹ ë¢°ë„

class SimpleSelfEvaluator:
    """ê°„ë‹¨í•œ AI ììœ¨ í‰ê°€ ì‹œìŠ¤í…œ"""
    
    def __init__(self, openai_client, deployment_name: str):
        self.openai_client = openai_client
        self.deployment_name = deployment_name
        self.min_score = 60  # ìµœì†Œ í†µê³¼ ì ìˆ˜
        
    def evaluate_answer(self, question: str, answer: str, context: Optional[Dict[str, Any]] = None) -> SimpleEvaluation:
        """ì§ˆë¬¸ê³¼ ë‹µë³€ë§Œìœ¼ë¡œ í‰ê°€"""
        
        try:
            logger.info(f"ğŸ” AI ììœ¨ í‰ê°€ ì‹œì‘: '{question[:50]}...'")
            
            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context_info = ""
            if context and isinstance(context, dict) and context.get("recent_conversations"):
                recent_queries = [conv["query"] for conv in context["recent_conversations"][-2:]]
                context_info = f"ìµœê·¼ ëŒ€í™” ë§¥ë½: {', '.join(recent_queries)}"
            
            # í‰ê°€ í”„ë¡¬í”„íŠ¸
            evaluation_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì ì ˆí•œì§€ í‰ê°€í•˜ì„¸ìš”:

**ì§ˆë¬¸**: {question}

**ë‹µë³€**: {answer}

**ë§¥ë½**: {context_info}

**í‰ê°€ ê¸°ì¤€**:
1. ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í–ˆëŠ”ê°€?
2. ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•œê°€?
3. ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í–ˆëŠ”ê°€?
4. í•„ìš”í•œ ì„¸ë¶€ì‚¬í•­ì´ í¬í•¨ë˜ì—ˆëŠ”ê°€?
5. ì´ì „ ëŒ€í™” ë§¥ë½ì„ ê³ ë ¤í–ˆëŠ”ê°€?
6. í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì˜ ì‹¤ì œ ì½”ë“œë¥¼ ë¶„ì„í–ˆëŠ”ê°€?
7. êµ¬ì²´ì ì¸ íŒŒì¼ëª…, í•¨ìˆ˜ëª…, í´ë˜ìŠ¤ëª…ì„ ì–¸ê¸‰í–ˆëŠ”ê°€?

**í‰ê°€ ë°©ë²•**:
- 0-100ì ìœ¼ë¡œ ì ìˆ˜ ë§¤ê¸°ê¸°
- 70ì  ì´ìƒì´ë©´ ì¶©ë¶„í•œ ë‹µë³€
- ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ì§€ì 
- ê° í•­ëª©ë‹¹ 100/7 ë§Œí¼ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì´ì ì„ ê³„ì‚°
- ê°œì„  ë°©í–¥ ì œì‹œ

**íŠ¹ë³„ ì£¼ì˜ì‚¬í•­**:
- ì½”ë“œ ê´€ë ¨ ì§ˆë¬¸ì˜ ê²½ìš° í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ì‹¤ì œ ì½”ë“œë¥¼ ë¶„ì„í–ˆëŠ”ì§€ í™•ì¸
- ì¼ë°˜ë¡ ë§Œ ì œê³µí•˜ê³  êµ¬ì²´ì ì¸ íŒŒì¼/í•¨ìˆ˜/í´ë˜ìŠ¤ë¥¼ ì–¸ê¸‰í•˜ì§€ ì•Šìœ¼ë©´ ë‚®ì€ ì ìˆ˜

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "score": 85,
    "is_sufficient": true,
    "missing_parts": ["êµ¬ì²´ì ì¸ ì‚¬ìš© ì˜ˆì‹œ", "ì„±ëŠ¥ íŠ¹ì„±"],
    "feedback": "ë‹µë³€ì´ ì „ë°˜ì ìœ¼ë¡œ ì¢‹ì§€ë§Œ, ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œì™€ ì„±ëŠ¥ íŠ¹ì„±ì„ ì¶”ê°€í•˜ë©´ ë” ë„ì›€ì´ ë  ê²ƒ ê°™ìŠµë‹ˆë‹¤.",
    "confidence": 0.9
}}
"""
            
            # LLM í‰ê°€ ì‹¤í–‰
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì½”ë“œ ë¶„ì„ ë‹µë³€ì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°ê´€ì ì´ê³  ì •í™•í•œ í‰ê°€ë¥¼ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": evaluation_prompt}
                ],
                temperature=0.1,  # ì¼ê´€ëœ í‰ê°€ë¥¼ ìœ„í•´ ë‚®ì€ temperature
                max_tokens=500
            )
            
            llm_response = response.choices[0].message.content
            evaluation = self._parse_evaluation(llm_response)
            
            logger.info(f"ğŸ“Š í‰ê°€ ê²°ê³¼: {evaluation.score:.1f}/100 (ì¶©ë¶„í•¨: {evaluation.is_sufficient})")
            if evaluation.missing_parts:
                logger.info(f"   - ë¶€ì¡±í•œ ë¶€ë¶„: {', '.join(evaluation.missing_parts)}")
            
            return evaluation
            
        except Exception as e:
            logger.error(f"í‰ê°€ ì‹¤íŒ¨: {e}")
            return self._create_default_evaluation()
    
    def _parse_evaluation(self, llm_response: str) -> SimpleEvaluation:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ í‰ê°€ ê²°ê³¼ ìƒì„±"""
        
        try:
            # JSON ì¶”ì¶œ
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                eval_data = json.loads(json_match.group())
                if isinstance(eval_data, dict):
                    return SimpleEvaluation(
                        score=float(eval_data.get("score", 0)),
                        is_sufficient=bool(eval_data.get("is_sufficient", False)),
                        missing_parts=eval_data.get("missing_parts", []),
                        feedback=eval_data.get("feedback", ""),
                        confidence=float(eval_data.get("confidence", 0.5))
                    )
                else:
                    return self._create_default_evaluation()
            else:
                logger.warning("í‰ê°€ ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return self._create_default_evaluation()
                
        except Exception as e:
            logger.error(f"í‰ê°€ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return self._create_default_evaluation()
    
    def _create_default_evaluation(self) -> SimpleEvaluation:
        """ê¸°ë³¸ í‰ê°€ ê²°ê³¼ ìƒì„±"""
        return SimpleEvaluation(
            score=50,
            is_sufficient=False,
            missing_parts=["í‰ê°€ ì‹¤íŒ¨"],
            feedback="í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            confidence=0.1
        )
    
    def improve_answer(self, question: str, current_answer: str, evaluation: SimpleEvaluation, 
                      context: Optional[Dict[str, Any]] = None, codechat_agent=None) -> str:
        """ë¶€ì¡±í•œ ë¶€ë¶„ì„ í¬í•¨í•˜ì—¬ ë‹µë³€ ê°œì„ """
        
        if evaluation.is_sufficient:
            logger.info("âœ… ë‹µë³€ì´ ì¶©ë¶„í•©ë‹ˆë‹¤. ê°œì„  ë¶ˆí•„ìš”.")
            return current_answer
        
        try:
            logger.info(f"ğŸ”§ ë‹µë³€ ê°œì„  ì‹œì‘: {evaluation.missing_parts}")
            
            # 1. ë¶€ì¡±í•œ ë¶€ë¶„ì— ëŒ€í•œ ì¶”ê°€ ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½
            search_plan = self._create_search_plan(question, evaluation, context)
            
            # 2. ì‹¤ì œ íˆ´ì„ ì‚¬ìš©í•œ ì¶”ê°€ ê²€ìƒ‰ (CodeChatAgentê°€ ì œê³µëœ ê²½ìš°)
            additional_info = ""
            if codechat_agent and search_plan and len(search_plan) > 0:
                logger.info(f"ğŸ” ì¶”ê°€ ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½ë¨: {len(search_plan)}ê°œ")
                try:
                    additional_info = self._execute_additional_search(
                        codechat_agent, search_plan, question, context
                    )
                except Exception as e:
                    logger.warning(f"âš ï¸ ì¶”ê°€ ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
                    additional_info = ""
            else:
                logger.info("â„¹ï¸ ì¶”ê°€ ê²€ìƒ‰ ì—†ìŒ (CodeChatAgent ì—†ìŒ ë˜ëŠ” ê²€ìƒ‰ ê³„íš ì—†ìŒ)")
                
                # fallback: ê²€ìƒ‰ ê³„íš ì—†ìœ¼ë©´ ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹œë„
                if codechat_agent and evaluation.missing_parts:
                    logger.info("ğŸ”„ fallback ê²€ìƒ‰ ì‹œë„")
                    try:
                        # ë¶€ì¡±í•œ ë¶€ë¶„ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ ê°„ë‹¨ ê²€ìƒ‰
                        keywords = []
                        for missing in evaluation.missing_parts[:2]:  # ìµœëŒ€ 2ê°œë§Œ
                            if "ì½”ë“œ" in missing or "í•¨ìˆ˜" in missing or "í´ë˜ìŠ¤" in missing:
                                keywords.append("main")  # ê¸°ë³¸ í‚¤ì›Œë“œ
                            elif "ë¶„ì„" in missing:
                                keywords.append("analysis")
                            elif "ì˜ˆì‹œ" in missing or "ì‚¬ìš©" in missing:
                                keywords.append("example")
                        
                        if keywords:
                            fallback_plan = [{"tool": "search_symbols_fts", "query": keywords[0], "reason": "fallback ê²€ìƒ‰"}]
                            additional_info = self._execute_additional_search(
                                codechat_agent, fallback_plan, question, context
                            )
                            logger.info("âœ… fallback ê²€ìƒ‰ ì™„ë£Œ")
                    except Exception as e:
                        logger.warning(f"fallback ê²€ìƒ‰ë„ ì‹¤íŒ¨: {e}")
            
            # 3. ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¤€ë¹„
            context_info = ""
            if context and isinstance(context, dict) and context.get("recent_conversations"):
                recent_queries = [conv["query"] for conv in context["recent_conversations"][-2:]]
                context_info = f"ìµœê·¼ ëŒ€í™” ë§¥ë½: {', '.join(recent_queries)}"
            
            # 4. ê°œì„  í”„ë¡¬í”„íŠ¸ (ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼ í¬í•¨)
            improvement_prompt = f"""
ë‹¤ìŒ ë‹µë³€ì„ ê°œì„ í•˜ì„¸ìš”:

**ì§ˆë¬¸**: {question}

**í˜„ì¬ ë‹µë³€**: {current_answer}

**ë¶€ì¡±í•œ ë¶€ë¶„**: {', '.join(evaluation.missing_parts)}

**ê°œì„  í”¼ë“œë°±**: {evaluation.feedback}

**ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼**: {additional_info if additional_info else "ì¶”ê°€ ê²€ìƒ‰ ì—†ìŒ"}

**ë§¥ë½**: {context_info}

**ê°œì„  ì›ì¹™**:
1. ê¸°ì¡´ ë‹µë³€ì˜ êµ¬ì¡°ì™€ íë¦„ì„ ìœ ì§€
2. ë¶€ì¡±í•œ ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€
3. ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ë‚´ìš© í¬í•¨
4. ì´ì „ ëŒ€í™” ë§¥ë½ ê³ ë ¤
5. ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í‘œí˜„ ì‚¬ìš©

ê°œì„ ëœ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”:
"""
            
            # 5. LLM ê°œì„  ì‹¤í–‰
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ë‹µë³€ì„ ê°œì„ í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë¶€ì¡±í•œ ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€í•˜ì—¬ ë” ì™„ì „í•œ ë‹µë³€ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": improvement_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            improved_answer = response.choices[0].message.content
            logger.info("âœ… ë‹µë³€ ê°œì„  ì™„ë£Œ")
            return improved_answer
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ê°œì„  ì‹¤íŒ¨: {e}")
            return current_answer
    
    def _create_search_plan(self, question: str, evaluation: SimpleEvaluation, context: Optional[Dict[str, Any]] = None) -> List[Dict[str, str]]:
        """ë¶€ì¡±í•œ ë¶€ë¶„ì— ëŒ€í•œ ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½"""
        
        try:
            search_plan_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì˜ ë‹µë³€ì—ì„œ ë¶€ì¡±í•œ ë¶€ë¶„ì„ ë³´ì™„í•˜ê¸° ìœ„í•œ ê²€ìƒ‰ ê³„íšì„ ìˆ˜ë¦½í•˜ì„¸ìš”:

**ì§ˆë¬¸**: {question}

**ë¶€ì¡±í•œ ë¶€ë¶„**: {', '.join(evaluation.missing_parts)}

**ê°œì„  í”¼ë“œë°±**: {evaluation.feedback}

**ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë“¤**:
- search_symbols_fts: í‚¤ì›Œë“œ ê²€ìƒ‰ (íŠ¹ì • í‚¤ì›Œë“œë¡œ ì½”ë“œ ê²€ìƒ‰)
- search_symbols_semantic: ì˜ë¯¸ ê²€ìƒ‰ (ì˜ë¯¸ ìœ ì‚¬ë„ë¡œ ì½”ë“œ ê²€ìƒ‰)
- get_artifact: ì‚°ì¶œë¬¼ ì¡°íšŒ (InsightGen ìƒì„± ë¬¸ì„œ ì¡°íšŒ)
  * ì‚¬ìš© ê°€ëŠ¥í•œ ì‚°ì¶œë¬¼ì€ list_artifacts ë„êµ¬ë¡œ í™•ì¸ í›„ ì ì ˆí•œ íŒŒì¼ ì„ íƒ
- analyze_source_code_with_llm: ì†ŒìŠ¤ì½”ë“œ ë¶„ì„ (ì†ŒìŠ¤ì½”ë“œë¥¼ LLMìœ¼ë¡œ ë¶„ì„)

ë¶€ì¡±í•œ ë¶€ë¶„ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ë¬´ì—‡ì„ ê²€ìƒ‰í•´ì•¼ í•˜ëŠ”ì§€ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ í¬í•¨ ê¸ˆì§€):

{{"searches": [{{"tool": "search_symbols_fts", "query": "main", "reason": "ì§„ì…ì  ì°¾ê¸°"}}]}}

ìµœëŒ€ 3ê°œì˜ ê²€ìƒ‰ê¹Œì§€ë§Œ í¬í•¨í•˜ì„¸ìš”.
"""
            
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ê²€ìƒ‰ ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."},
                    {"role": "user", "content": search_plan_prompt}
                ],
                temperature=0.1,
                max_tokens=200
            )
            
            llm_response = response.choices[0].message.content
            return self._parse_search_plan(llm_response)
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ê³„íš ìˆ˜ë¦½ ì‹¤íŒ¨: {e}")
            return []
    
    def _parse_search_plan(self, llm_response: str) -> List[Dict[str, str]]:
        """ê²€ìƒ‰ ê³„íš íŒŒì‹± (ê²¬ê³ í•œ JSON ì²˜ë¦¬)"""
        
        try:
            import re
            
            # ì•ˆì „í•œ JSON ì¶”ì¶œì„ ìœ„í•œ ì—¬ëŸ¬ ì‹œë„
            json_candidates = []
            
            # 1. searches í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì™„ì „í•œ JSON ë¸”ë¡ ì°¾ê¸°
            complete_json_match = re.search(r'\{[^{}]*"searches"[^{}]*:\s*\[[^\]]*\][^{}]*\}', llm_response, re.DOTALL)
            if complete_json_match:
                json_candidates.append(complete_json_match.group())
            
            # 2. ì¤‘ê´„í˜¸ ê· í˜•ì´ ë§ëŠ” JSON ë¸”ë¡ë“¤ ì°¾ê¸°
            brace_matches = []
            brace_count = 0
            start_pos = -1
            
            for i, char in enumerate(llm_response):
                if char == '{':
                    if brace_count == 0:
                        start_pos = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_pos != -1:
                        candidate = llm_response[start_pos:i+1]
                        if '"searches"' in candidate:
                            brace_matches.append(candidate)
                        start_pos = -1
            
            json_candidates.extend(brace_matches)
            
            # 3. ê° JSON í›„ë³´ ì‹œë„
            for i, json_str in enumerate(json_candidates):
                try:
                    logger.info(f"ğŸ” JSON í›„ë³´ {i+1} íŒŒì‹± ì‹œë„ (ê¸¸ì´: {len(json_str)})")
                    
                    # ì˜ë¦° JSON ìˆ˜ì • ì‹œë„
                    if not json_str.endswith('}'):
                        # ë§ˆì§€ë§‰ ì™„ì „í•œ ê°ì²´ê¹Œì§€ë§Œ ì‚¬ìš©
                        last_complete_obj = json_str.rfind('}')
                        if last_complete_obj > 0:
                            json_str = json_str[:last_complete_obj + 1]
                    
                    plan_data = json.loads(json_str)
                    
                    if isinstance(plan_data, dict):
                        searches = plan_data.get("searches", [])
                        if isinstance(searches, list) and len(searches) > 0:
                            # ê° ê²€ìƒ‰ í•­ëª©ì´ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸
                            valid_searches = []
                            for search in searches:
                                if isinstance(search, dict) and "tool" in search:
                                    valid_searches.append(search)
                            
                            if valid_searches:
                                logger.info(f"âœ… ê²€ìƒ‰ ê³„íš íŒŒì‹± ì„±ê³µ: {len(valid_searches)}ê°œ ê³„íš")
                                return valid_searches
                    
                except json.JSONDecodeError as e:
                    logger.warning(f"   JSON í›„ë³´ {i+1} íŒŒì‹± ì‹¤íŒ¨: {e}")
                    continue
                except Exception as e:
                    logger.warning(f"   JSON í›„ë³´ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            # 4. ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ì‹œ - ê°œë³„ ê²€ìƒ‰ ëª…ë ¹ì–´ ì¶”ì¶œ ì‹œë„
            logger.warning("âŒ JSON íŒŒì‹± ëª¨ë‘ ì‹¤íŒ¨ - ê°œë³„ ëª…ë ¹ì–´ ì¶”ì¶œ ì‹œë„")
            
            # ê°„ë‹¨í•œ íŒ¨í„´ìœ¼ë¡œ ë„êµ¬ëª…ê³¼ ì¿¼ë¦¬ ì¶”ì¶œ
            tool_patterns = [
                r'"tool":\s*"([^"]+)"',
                r'search_symbols_fts[^"]*"([^"]+)"',
                r'search_symbols_semantic[^"]*"([^"]+)"'
            ]
            
            fallback_searches = []
            for pattern in tool_patterns:
                matches = re.findall(pattern, llm_response)
                for match in matches:
                    if match and len(fallback_searches) < 3:  # ìµœëŒ€ 3ê°œê¹Œì§€
                        fallback_searches.append({
                            "tool": "search_symbols_fts",
                            "query": match,
                            "reason": "LLM ì‘ë‹µì—ì„œ ì¶”ì¶œ"
                        })
            
            if fallback_searches:
                logger.info(f"ğŸ”„ fallback ê²€ìƒ‰ ê³„íš ì‚¬ìš©: {len(fallback_searches)}ê°œ")
                return fallback_searches
            
            logger.warning("âŒ ëª¨ë“  ê²€ìƒ‰ ê³„íš ì¶”ì¶œ ì‹¤íŒ¨")
            return []
                
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ê³„íš íŒŒì‹± ì „ì²´ ì‹¤íŒ¨: {e}")
            return []
    
    def _execute_additional_search(self, codechat_agent, search_plan: List[Dict[str, str]], 
                                 question: str, context: Optional[Dict[str, Any]] = None) -> str:
        """AIê°€ ì„ íƒí•œ íˆ´ë¡œ ì¶”ê°€ ê²€ìƒ‰ ì‹¤í–‰"""
        
        try:
            search_results = []
            
            # search_planì´ Noneì´ê±°ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²˜ë¦¬
            if not search_plan or not isinstance(search_plan, list):
                logger.warning("âŒ ê²€ìƒ‰ ê³„íšì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
                return "ê²€ìƒ‰ ê³„íš ì—†ìŒ"
            
            logger.info(f"ğŸ” ê²€ìƒ‰ ê³„íš ì‹¤í–‰ ì‹œì‘: {len(search_plan)}ê°œ ê³„íš")
            
            for i, search in enumerate(search_plan):
                if not isinstance(search, dict):
                    logger.warning(f"âŒ ê²€ìƒ‰ ê³„íš {i+1}ì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜: {search}")
                    continue
                    
                tool = search.get("tool")
                query = search.get("query", question)
                reason = search.get("reason", "ê°œì„ ì„ ìœ„í•œ ì¶”ê°€ ê²€ìƒ‰")
                
                if not tool:
                    logger.warning(f"âŒ ê²€ìƒ‰ ê³„íš {i+1}ì— toolì´ ì—†ìŒ: {search}")
                    continue
                
                logger.info(f"ğŸ” ì¶”ê°€ ê²€ìƒ‰ ì‹¤í–‰: {tool} - {query} ({reason})")
                
                # AIê°€ ì„ íƒí•œ íˆ´ì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì‹¤í–‰
                result = self._execute_single_search(codechat_agent, tool, query, reason)
                if result:
                    search_results.append(result)
            
            if search_results:
                logger.info(f"âœ… ì¶”ê°€ ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
                return "\n".join(search_results)
            else:
                logger.warning("âŒ ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return "ì¶”ê°€ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ê°€ ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return "ì¶”ê°€ ê²€ìƒ‰ ì‹¤íŒ¨"
    
    def _execute_single_search(self, codechat_agent, tool: str, query: str, reason: str) -> str:
        """ë‹¨ì¼ ê²€ìƒ‰ ì‹¤í–‰ - AIê°€ ì„ íƒí•œ íˆ´ì— ë”°ë¼ ë™ì  ì‹¤í–‰"""
        
        try:
            # ì‚¬ìš© ê°€ëŠ¥í•œ íˆ´ë“¤ì„ ë™ì ìœ¼ë¡œ ë§¤í•‘
            tool_mapping = {
                "search_symbols_fts": self._execute_fts_search,
                "search_symbols_semantic": self._execute_semantic_search,
                "get_symbol": self._execute_get_symbol,
                "get_calls_from": self._execute_get_calls_from,
                "get_calls_to": self._execute_get_calls_to,
                "analyze_symbol_llm": self._execute_analyze_symbol_llm,
                "analyze_file_llm": self._execute_analyze_file_llm,
                "analyze_chunk_llm": self._execute_analyze_chunk_llm,
                "get_artifact": self._execute_get_artifact,
                "list_artifacts": self._execute_list_artifacts,
                "get_artifact_summary": self._execute_get_artifact_summary
            }
            
            # AIê°€ ì„ íƒí•œ íˆ´ ì‹¤í–‰
            if tool in tool_mapping:
                return tool_mapping[tool](codechat_agent, query, reason)
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” íˆ´: {tool}")
                return f"ì•Œ ìˆ˜ ì—†ëŠ” íˆ´: {tool}"
                
        except Exception as e:
            logger.error(f"íˆ´ ì‹¤í–‰ ì‹¤íŒ¨ ({tool}): {e}")
            return f"íˆ´ ì‹¤í–‰ ì‹¤íŒ¨: {tool}"
    
    def _execute_fts_search(self, codechat_agent, query: str, reason: str) -> str:
        """FTS ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            results = codechat_agent._fts_search(query, 3)
            if results:
                return f"í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ({query}): {len(results)}ê°œ ë°œê²¬ - {reason}"
            else:
                return f"í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {query}"
        except Exception as e:
            return f"FTS ê²€ìƒ‰ ì‹¤íŒ¨: {e}"
    
    def _execute_semantic_search(self, codechat_agent, query: str, reason: str) -> str:
        """ì˜ë¯¸ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            results = codechat_agent._faiss_search(query, 3)
            if results:
                return f"ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ({query}): {len(results)}ê°œ ë°œê²¬ - {reason}"
            else:
                return f"ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: {query}"
        except Exception as e:
            return f"ì˜ë¯¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}"
    
    def _execute_get_symbol(self, codechat_agent, query: str, reason: str) -> str:
        """ì‹¬ë³¼ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        try:
            # ì‹¬ë³¼ëª… ì¶”ì¶œ (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            symbol_name = query.split()[0] if query.split() else query
            result = codechat_agent.sqlite_store.get_symbol(symbol_name)
            if result:
                return f"ì‹¬ë³¼ ì •ë³´ ({symbol_name}): {result.get('symbol_type', 'unknown')} - {reason}"
            else:
                return f"ì‹¬ë³¼ ì •ë³´ ì—†ìŒ: {symbol_name}"
        except Exception as e:
            return f"ì‹¬ë³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    def _execute_get_calls_from(self, codechat_agent, query: str, reason: str) -> str:
        """í˜¸ì¶œ ê´€ê³„ ì¡°íšŒ (from)"""
        try:
            symbol_name = query.split()[0] if query.split() else query
            results = codechat_agent.sqlite_store.get_calls_from(symbol_name)
            if results:
                return f"í˜¸ì¶œ ê´€ê³„ ({symbol_name}): {len(results)}ê°œ í˜¸ì¶œ - {reason}"
            else:
                return f"í˜¸ì¶œ ê´€ê³„ ì—†ìŒ: {symbol_name}"
        except Exception as e:
            return f"í˜¸ì¶œ ê´€ê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    def _execute_get_calls_to(self, codechat_agent, query: str, reason: str) -> str:
        """í˜¸ì¶œ ê´€ê³„ ì¡°íšŒ (to)"""
        try:
            symbol_name = query.split()[0] if query.split() else query
            results = codechat_agent.sqlite_store.get_calls_to(symbol_name)
            if results:
                return f"í˜¸ì¶œë°›ëŠ” ê´€ê³„ ({symbol_name}): {len(results)}ê°œ í˜¸ì¶œ - {reason}"
            else:
                return f"í˜¸ì¶œë°›ëŠ” ê´€ê³„ ì—†ìŒ: {symbol_name}"
        except Exception as e:
            return f"í˜¸ì¶œë°›ëŠ” ê´€ê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    def _execute_analyze_symbol_llm(self, codechat_agent, query: str, reason: str) -> str:
        """LLM ì‹¬ë³¼ ë¶„ì„"""
        try:
            # ê°„ë‹¨í•œ LLM ë¶„ì„ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ë¡œì§ í•„ìš”)
            return f"LLM ì‹¬ë³¼ ë¶„ì„ ê²°ê³¼: {query}ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ - {reason}"
        except Exception as e:
            return f"LLM ì‹¬ë³¼ ë¶„ì„ ì‹¤íŒ¨: {e}"
    
    def _execute_analyze_file_llm(self, codechat_agent, query: str, reason: str) -> str:
        """LLM íŒŒì¼ ë¶„ì„"""
        try:
            return f"LLM íŒŒì¼ ë¶„ì„ ê²°ê³¼: {query}ì— ëŒ€í•œ íŒŒì¼ ë¶„ì„ - {reason}"
        except Exception as e:
            return f"LLM íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}"
    
    def _execute_analyze_chunk_llm(self, codechat_agent, query: str, reason: str) -> str:
        """LLM ì²­í¬ ë¶„ì„"""
        try:
            return f"LLM ì²­í¬ ë¶„ì„ ê²°ê³¼: {query}ì— ëŒ€í•œ ì²­í¬ ë¶„ì„ - {reason}"
        except Exception as e:
            return f"LLM ì²­í¬ ë¶„ì„ ì‹¤íŒ¨: {e}"
    
    def _execute_get_artifact(self, codechat_agent, query: str, reason: str) -> str:
        """ì‚°ì¶œë¬¼ ì¡°íšŒ"""
        try:
            # InsightGen ë„êµ¬ ì‚¬ìš© (ê°„ë‹¨í•œ ì˜ˆì‹œ)
            return f"ì‚°ì¶œë¬¼ ì¡°íšŒ ê²°ê³¼: {query} ê´€ë ¨ ë¬¸ì„œ - {reason}"
        except Exception as e:
            return f"ì‚°ì¶œë¬¼ ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    def _execute_list_artifacts(self, codechat_agent, query: str, reason: str) -> str:
        """ì‚°ì¶œë¬¼ ëª©ë¡ ì¡°íšŒ"""
        try:
            return f"ì‚°ì¶œë¬¼ ëª©ë¡: {query} ê´€ë ¨ ë¬¸ì„œë“¤ - {reason}"
        except Exception as e:
            return f"ì‚°ì¶œë¬¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    def _execute_get_artifact_summary(self, codechat_agent, query: str, reason: str) -> str:
        """ì‚°ì¶œë¬¼ ìš”ì•½ ì¡°íšŒ"""
        try:
            return f"ì‚°ì¶œë¬¼ ìš”ì•½: {query} ê´€ë ¨ ë¬¸ì„œ ìš”ì•½ - {reason}"
        except Exception as e:
            return f"ì‚°ì¶œë¬¼ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}"
    
    def evaluate_and_improve(self, question: str, answer: str, context: Optional[Dict[str, Any]] = None, codechat_agent=None, attempt_number: int = 1) -> Tuple[str, SimpleEvaluation]:
        """í‰ê°€í•˜ê³  í•„ìš”ì‹œ ê°œì„ """
        
        logger.info(f"ğŸ” ì‹œë„ {attempt_number}: ë‹µë³€ í‰ê°€ ë° ê°œì„ ")
        
        # 1. í‰ê°€
        evaluation = self.evaluate_answer(question, answer, context)
        
        # 2. ê°œì„  (í•„ìš”ì‹œ ë˜ëŠ” ì‹œë„ íšŸìˆ˜ì— ë”°ë¼)
        should_improve = (
            not evaluation.is_sufficient or  # ì ìˆ˜ê°€ ë‚®ê±°ë‚˜
            (attempt_number > 1 and evaluation.score < 70.0)  # 2ë²ˆì§¸ ì´í›„ ì‹œë„ì—ì„œëŠ” 90ì  ë¯¸ë§Œì´ë©´ ê°œì„ 
        )
        
        if should_improve:
            logger.info(f"   ì ìˆ˜ {evaluation.score:.1f}ì  - ê°œì„  í•„ìš”")
            improved_answer = self.improve_answer(question, answer, evaluation, context, codechat_agent)
            
            # ê°œì„ ëœ ë‹µë³€ ì¬í‰ê°€
            logger.info(f"   ê°œì„ ëœ ë‹µë³€ ì¬í‰ê°€")
            new_evaluation = self.evaluate_answer(question, improved_answer, context)
            
            # ê°œì„  ì „í›„ ë¹„êµ
            if new_evaluation.score > evaluation.score:
                logger.info(f"   ê°œì„  ì„±ê³µ: {evaluation.score:.1f} â†’ {new_evaluation.score:.1f}ì ")
                return improved_answer, new_evaluation
            else:
                logger.info(f"   ê°œì„  íš¨ê³¼ ì—†ìŒ: {evaluation.score:.1f} â‰¥ {new_evaluation.score:.1f}ì , ì›ë³¸ ìœ ì§€")
                return answer, evaluation
        else:
            logger.info(f"   ì ìˆ˜ {evaluation.score:.1f}ì  - ê°œì„  ë¶ˆí•„ìš”")
            return answer, evaluation
