"""
AI ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ - LLMì´ ëŒ€í™” ë§¥ë½ì„ í•™ìŠµí•˜ê³  ì§€ëŠ¥ì ìœ¼ë¡œ í™œìš©
"""

import logging
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
import json
import time
from collections import deque
import hashlib
import re

logger = logging.getLogger(__name__)

@dataclass
class AIConversationContext:
    """AI ëŒ€í™” ì»¨í…ìŠ¤íŠ¸"""
    session_id: str
    user_id: Optional[str]
    conversation_history: List[Dict[str, Any]]
    learned_patterns: Dict[str, Any]
    user_preferences: Dict[str, Any]
    context_insights: Dict[str, Any]
    created_at: float
    updated_at: float

@dataclass
class AIContextInsight:
    """AI ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸"""
    insight_type: str  # pattern, preference, relationship, trend
    content: str
    confidence: float
    source: str
    timestamp: float

class AIContextManager:
    """AI ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì"""
    
    def __init__(self, openai_client, deployment_name: str, max_context_size: int = 20):
        self.openai_client = openai_client
        self.deployment_name = deployment_name
        self.max_context_size = max_context_size
        self.contexts: Dict[str, AIConversationContext] = {}
        
    def get_or_create_context(self, session_id: str, user_id: Optional[str] = None) -> AIConversationContext:
        """ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if session_id not in self.contexts:
            self.contexts[session_id] = AIConversationContext(
                session_id=session_id,
                user_id=user_id,
                conversation_history=[],
                learned_patterns={},
                user_preferences={},
                context_insights={},
                created_at=time.time(),
                updated_at=time.time()
            )
            logger.info(f"ìƒˆë¡œìš´ AI ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {session_id}")
        
        return self.contexts[session_id]
    
    def analyze_and_update_context(self, session_id: str, query: str, answer: str, 
                                 search_results: Optional[List[Any]] = None) -> Dict[str, Any]:
        """AIê°€ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ê³  ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            logger.info(f"ğŸ§  AI ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘: {session_id}")
            
            context = self.get_or_create_context(session_id)
            
            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
            conversation_entry = {
                "timestamp": time.time(),
                "query": query,
                "answer": answer,
                "query_length": len(query),
                "answer_length": len(answer),
                "search_results_count": len(search_results) if search_results else 0
            }
            context.conversation_history.append(conversation_entry)
            
            # ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì œí•œ
            if len(context.conversation_history) > self.max_context_size:
                context.conversation_history = context.conversation_history[-self.max_context_size:]
            
            # AI ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
            context_analysis = self._ai_analyze_context(context, query, answer, search_results)
            
            # í•™ìŠµëœ íŒ¨í„´ ì—…ë°ì´íŠ¸
            self._update_learned_patterns(context, context_analysis)
            
            # ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸
            self._update_user_preferences(context, context_analysis)
            
            # ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ì—…ë°ì´íŠ¸
            self._update_context_insights(context, context_analysis)
            
            context.updated_at = time.time()
            
            logger.info(f"âœ… AI ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ: {session_id}")
            return context_analysis
            
        except Exception as e:
            logger.error(f"âŒ AI ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_context_for_query(self, session_id: str, query: str) -> Dict[str, Any]:
        """ì§ˆë¬¸ì— ëŒ€í•œ AI ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ë°˜í™˜"""
        context = self.get_or_create_context(session_id)
        
        # AI ì»¨í…ìŠ¤íŠ¸ ì¶”ì²œ
        context_recommendations = self._ai_recommend_context(context, query)
        
        return {
            "session_id": session_id,
            "conversation_history": context.conversation_history[-5:],  # ìµœê·¼ 5ê°œ
            "learned_patterns": context.learned_patterns,
            "user_preferences": context.user_preferences,
            "context_insights": context.context_insights,
            "recommendations": context_recommendations,
            "context_age": time.time() - context.created_at
        }
    
    def _ai_analyze_context(self, context: AIConversationContext, query: str, 
                          answer: str, search_results: Optional[List[Any]]) -> Dict[str, Any]:
        """AIê°€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„"""
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½
            history_summary = self._summarize_conversation_history(context.conversation_history)
            
            # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸
            analysis_prompt = f"""
ë‹¤ìŒ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ íŒ¨í„´ê³¼ ì„ í˜¸ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.

í˜„ì¬ ì§ˆë¬¸: {query}
í˜„ì¬ ë‹µë³€: {answer[:200]}...
ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(search_results) if search_results else 0}

ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½:
{history_summary}

ê¸°ì¡´ í•™ìŠµëœ íŒ¨í„´:
{json.dumps(context.learned_patterns, ensure_ascii=False, indent=2)}

ê¸°ì¡´ ì‚¬ìš©ì ì„ í˜¸ë„:
{json.dumps(context.user_preferences, ensure_ascii=False, indent=2)}

ë¶„ì„í•´ì•¼ í•  ìš”ì†Œë“¤:
1. ì§ˆë¬¸ ìœ í˜• íŒ¨í„´ (ì •ë³´ ìš”ì²­, ë¶„ì„, ì„¤ëª…, ë””ë²„ê¹… ë“±)
2. ì„ í˜¸í•˜ëŠ” ë‹µë³€ ìŠ¤íƒ€ì¼ (ê°„ê²°í•¨, ìƒì„¸í•¨, ê¸°ìˆ ì , ë¹„ê¸°ìˆ ì )
3. ê´€ì‹¬ ìˆëŠ” ì£¼ì œë‚˜ ë„ë©”ì¸
4. ì§ˆë¬¸ì˜ ë³µì¡ë„ ë³€í™” ì¶”ì´
5. ë§Œì¡±ë„ ì§€í‘œ (ë‹µë³€ ê¸¸ì´, ê²€ìƒ‰ ê²°ê³¼ í™œìš©ë„)
6. ëŒ€í™” íë¦„ íŒ¨í„´

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "question_patterns": {{
        "common_types": ["information", "analysis"],
        "complexity_trend": "increasing|decreasing|stable",
        "domain_focus": ["backend", "frontend", "database"]
    }},
    "preference_insights": {{
        "answer_style": "concise|detailed|technical|casual",
        "detail_level": "high|medium|low",
        "preferred_tools": ["search_symbols_fts", "analyze_symbol_llm"]
    }},
    "conversation_flow": {{
        "follow_up_likelihood": 0.8,
        "topic_consistency": 0.7,
        "complexity_progression": "linear|exponential|random"
    }},
    "satisfaction_indicators": {{
        "answer_length_preference": "short|medium|long",
        "search_result_utilization": 0.6,
        "technical_depth_preference": "high|medium|low"
    }},
    "recommendations": [
        "ì‚¬ìš©ìê°€ ìƒì„¸í•œ ì„¤ëª…ì„ ì„ í˜¸í•˜ë¯€ë¡œ ë‹µë³€ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì œê³µ",
        "ë°±ì—”ë“œ ê´€ë ¨ ì§ˆë¬¸ì´ ë§ìœ¼ë¯€ë¡œ ê´€ë ¨ ë„êµ¬ ìš°ì„  ì‚¬ìš©"
    ]
}}
"""
            
            # LLM ë¶„ì„ ì‹¤í–‰
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íŒ¨í„´ê³¼ ì„ í˜¸ë„ë¥¼ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”."},
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.2,
                max_tokens=1000
            )
            
            llm_response = response.choices[0].message.content
            analysis_data = self._parse_context_analysis(llm_response)
            
            return analysis_data
            
        except Exception as e:
            logger.error(f"AI ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _summarize_conversation_history(self, history: List[Dict[str, Any]]) -> str:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½"""
        if not history:
            return "ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        recent_queries = [entry["query"] for entry in history[-5:]]
        avg_query_length = sum(entry["query_length"] for entry in history) / len(history)
        avg_answer_length = sum(entry["answer_length"] for entry in history) / len(history)
        
        return f"""
ìµœê·¼ ì§ˆë¬¸ë“¤: {', '.join(recent_queries)}
í‰ê·  ì§ˆë¬¸ ê¸¸ì´: {avg_query_length:.1f}ì
í‰ê·  ë‹µë³€ ê¸¸ì´: {avg_answer_length:.1f}ì
ì´ ëŒ€í™” ìˆ˜: {len(history)}ê°œ
"""
    
    def _parse_context_analysis(self, llm_response: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ"""
        try:
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                logger.warning("ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return {}
                
        except Exception as e:
            logger.error(f"ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {}
    
    def _update_learned_patterns(self, context: AIConversationContext, analysis: Dict[str, Any]):
        """í•™ìŠµëœ íŒ¨í„´ ì—…ë°ì´íŠ¸"""
        if "question_patterns" in analysis:
            patterns = analysis["question_patterns"]
            
            # ì§ˆë¬¸ ìœ í˜• íŒ¨í„´ ì—…ë°ì´íŠ¸
            if "common_types" in patterns:
                if "question_types" not in context.learned_patterns:
                    context.learned_patterns["question_types"] = {}
                
                for qtype in patterns["common_types"]:
                    context.learned_patterns["question_types"][qtype] = \
                        context.learned_patterns["question_types"].get(qtype, 0) + 1
            
            # ë³µì¡ë„ ì¶”ì´ ì—…ë°ì´íŠ¸
            if "complexity_trend" in patterns:
                context.learned_patterns["complexity_trend"] = patterns["complexity_trend"]
            
            # ë„ë©”ì¸ í¬ì»¤ìŠ¤ ì—…ë°ì´íŠ¸
            if "domain_focus" in patterns:
                if "domains" not in context.learned_patterns:
                    context.learned_patterns["domains"] = {}
                
                for domain in patterns["domain_focus"]:
                    context.learned_patterns["domains"][domain] = \
                        context.learned_patterns["domains"].get(domain, 0) + 1
    
    def _update_user_preferences(self, context: AIConversationContext, analysis: Dict[str, Any]):
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì—…ë°ì´íŠ¸"""
        if "preference_insights" in analysis:
            preferences = analysis["preference_insights"]
            
            # ë‹µë³€ ìŠ¤íƒ€ì¼ ì„ í˜¸ë„
            if "answer_style" in preferences:
                context.user_preferences["answer_style"] = preferences["answer_style"]
            
            # ìƒì„¸ë„ ì„ í˜¸ë„
            if "detail_level" in preferences:
                context.user_preferences["detail_level"] = preferences["detail_level"]
            
            # ì„ í˜¸í•˜ëŠ” ë„êµ¬ë“¤
            if "preferred_tools" in preferences:
                if "tools" not in context.user_preferences:
                    context.user_preferences["tools"] = []
                
                for tool in preferences["preferred_tools"]:
                    if tool not in context.user_preferences["tools"]:
                        context.user_preferences["tools"].append(tool)
    
    def _update_context_insights(self, context: AIConversationContext, analysis: Dict[str, Any]):
        """ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸ ì—…ë°ì´íŠ¸"""
        if "recommendations" in analysis:
            context.context_insights["recommendations"] = analysis["recommendations"]
        
        if "conversation_flow" in analysis:
            context.context_insights["conversation_flow"] = analysis["conversation_flow"]
        
        if "satisfaction_indicators" in analysis:
            context.context_insights["satisfaction_indicators"] = analysis["satisfaction_indicators"]
    
    def _ai_recommend_context(self, context: AIConversationContext, query: str) -> Dict[str, Any]:
        """AIê°€ ì§ˆë¬¸ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì²œ"""
        try:
            # AI ì¶”ì²œ í”„ë¡¬í”„íŠ¸
            recommendation_prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ê¸°ì¡´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œì‚¬í•­ì„ ì œê³µí•˜ì„¸ìš”.

í˜„ì¬ ì§ˆë¬¸: {query}

í•™ìŠµëœ íŒ¨í„´:
{json.dumps(context.learned_patterns, ensure_ascii=False, indent=2)}

ì‚¬ìš©ì ì„ í˜¸ë„:
{json.dumps(context.user_preferences, ensure_ascii=False, indent=2)}

ì»¨í…ìŠ¤íŠ¸ ì¸ì‚¬ì´íŠ¸:
{json.dumps(context.context_insights, ensure_ascii=False, indent=2)}

ì¶”ì²œí•´ì•¼ í•  ìš”ì†Œë“¤:
1. ì ì ˆí•œ ë„êµ¬ ì„ íƒ
2. ë‹µë³€ ìŠ¤íƒ€ì¼ ì¡°ì •
3. ìƒì„¸ë„ ë ˆë²¨
4. ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ í™œìš©
5. í›„ì† ì§ˆë¬¸ ì œì•ˆ

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ:
{{
    "recommended_tools": ["search_symbols_fts", "analyze_symbol_llm"],
    "answer_style": "detailed",
    "detail_level": "high",
    "context_hints": ["ì´ì „ì— ë°±ì—”ë“œ ê´€ë ¨ ì§ˆë¬¸ì„ ë§ì´ í–ˆìŒ"],
    "follow_up_suggestions": ["ê´€ë ¨ í•¨ìˆ˜ë“¤ì˜ í˜¸ì¶œ ê´€ê³„ëŠ”?", "ì„±ëŠ¥ ìµœì í™” ë°©ë²•ì€?"]
}}
"""
            
            # LLM ì¶”ì²œ ì‹¤í–‰
            response = self.openai_client.chat.completions.create(
                model=self.deployment_name,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì ì˜ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": recommendation_prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            llm_response = response.choices[0].message.content
            return self._parse_context_analysis(llm_response)
            
        except Exception as e:
            logger.error(f"AI ì»¨í…ìŠ¤íŠ¸ ì¶”ì²œ ì‹¤íŒ¨: {e}")
            return {}
    
    def clear_context(self, session_id: str) -> None:
        """ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”"""
        if session_id in self.contexts:
            del self.contexts[session_id]
        logger.info(f"AI ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”: {session_id}")
    
    def get_context_stats(self) -> Dict[str, Any]:
        """ì»¨í…ìŠ¤íŠ¸ í†µê³„ ë°˜í™˜"""
        total_sessions = len(self.contexts)
        active_sessions = sum(1 for ctx in self.contexts.values() 
                            if time.time() - ctx.updated_at < 3600)  # 1ì‹œê°„ ì´ë‚´
        
        return {
            "total_sessions": total_sessions,
            "active_sessions": active_sessions,
            "max_context_size": self.max_context_size
        }
